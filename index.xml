<?xml version="1.0" encoding="UTF-8"?>
<rss  xmlns:atom="http://www.w3.org/2005/Atom" 
      xmlns:media="http://search.yahoo.com/mrss/" 
      xmlns:content="http://purl.org/rss/1.0/modules/content/" 
      xmlns:dc="http://purl.org/dc/elements/1.1/" 
      version="2.0">
<channel>
<title>Lucas van Walstijn</title>
<link>https://lucasvw.github.io/index.html</link>
<atom:link href="https://lucasvw.github.io/index.xml" rel="self" type="application/rss+xml"/>
<description></description>
<generator>quarto-1.3.433</generator>
<lastBuildDate>Mon, 03 Jul 2023 00:00:00 GMT</lastBuildDate>
<item>
  <title>Introduction to Stable Diffusion - Code</title>
  <dc:creator>Lucas van Walstijn</dc:creator>
  <link>https://lucasvw.github.io/posts/07_stable_diffusion_code/index.html</link>
  <description><![CDATA[ 




<p>In the previous blog <a href="https://lucasvw.github.io/posts/06_stable_diffusion_basics/">post</a>, the main components and some intuition behind Stable Diffusion were introduced. Now, let’s see how we can use the HuggingFace diffusers library to generate images. The content of this blog post is based on <a href="https://course.fast.ai/Lessons/lesson9.html">Lesson 9</a> and <a href="https://course.fast.ai/Lessons/lesson10.html">Lesson 10</a> of Deep Learning for Coders. The end-to-end pipeline is very practical and easy to use, it’s basically a one-liner. We create a diffusion pipeline by downloading pre-trained models from a repo in the HuggingFace hub. Then, we can call this <code>pipe</code> object with a certain prompt:</p>
<div class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># pip install diffusers==0.12.1</span></span>
<span id="cb1-2"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># pip install accelerate</span></span>
<span id="cb1-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># pip install transformers==4.25.1</span></span>
<span id="cb1-4"></span>
<span id="cb1-5"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> torchvision <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> transforms <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> tfms</span>
<span id="cb1-6"></span>
<span id="cb1-7"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> matplotlib.pyplot <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> plt</span>
<span id="cb1-8"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> torch</span>
<span id="cb1-9"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> diffusers <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> StableDiffusionPipeline</span>
<span id="cb1-10"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> PIL <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> Image</span>
<span id="cb1-11"></span>
<span id="cb1-12">num_inference_steps <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">50</span></span>
<span id="cb1-13">batch_size <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span></span>
<span id="cb1-14"></span>
<span id="cb1-15">pipe <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> StableDiffusionPipeline.from_pretrained(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"CompVis/stable-diffusion-v1-4"</span>).to(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"cuda"</span>)</span>
<span id="cb1-16"></span>
<span id="cb1-17">prompt <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Homer from the Simpsons on his roadbike climbing a mountain in the Pyrenees"</span></span></code></pre></div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"44fb9aaa15514337bfd8381b8c89186d","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>The config attributes {'scaling_factor': 0.18215} were passed to AutoencoderKL, but are not expected and will be ignored. Please verify your config.json configuration file.</code></pre>
</div>
</div>
<div class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1">torch.manual_seed(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">114</span>)</span>
<span id="cb3-2">pipe(prompt, num_inference_steps<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>num_inference_steps, guidance_scale<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">7.5</span>).images[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]</span></code></pre></div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"6a59a45858794244a0e7e5a06fc5db01","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display" data-execution_count="9">
<p><img src="https://lucasvw.github.io/posts/07_stable_diffusion_code/index_files/figure-html/cell-3-output-2.png" class="img-fluid"></p>
</div>
</div>
<p>Not bad, but not great either. Let’s dive one layer deeper, and create the components described in the previous <a href="https://lucasvw.github.io/posts/06_stable_diffusion_basics/">post</a>: the Unet, the autoencoder, text encoder and noise scheduler:</p>
<div class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> diffusers <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> AutoencoderKL, LMSDiscreteScheduler, UNet2DConditionModel</span>
<span id="cb4-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> transformers <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> CLIPTextModel, CLIPTokenizer, logging</span>
<span id="cb4-3"></span>
<span id="cb4-4">logging.set_verbosity_error()</span>
<span id="cb4-5"></span>
<span id="cb4-6"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Autoencoder, to go from image -&gt; latents (encoder) and back (decoder)</span></span>
<span id="cb4-7">vae <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> AutoencoderKL.from_pretrained(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"CompVis/stable-diffusion-v1-4"</span>, subfolder<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"vae"</span>).to(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"cuda"</span>)</span>
<span id="cb4-8"></span>
<span id="cb4-9"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># UNet, to predict the noise (latents) from noisy image (latents)</span></span>
<span id="cb4-10">unet <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> UNet2DConditionModel.from_pretrained(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"CompVis/stable-diffusion-v1-4"</span>, subfolder<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"unet"</span>).to(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"cuda"</span>)</span>
<span id="cb4-11"></span>
<span id="cb4-12"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Tokenizer and Text encoder to create prompt embeddings</span></span>
<span id="cb4-13">tokenizer <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> CLIPTokenizer.from_pretrained(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"openai/clip-vit-large-patch14"</span>)</span>
<span id="cb4-14">text_encoder <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> CLIPTextModel.from_pretrained(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"openai/clip-vit-large-patch14"</span>).to(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"cuda"</span>)</span>
<span id="cb4-15"></span>
<span id="cb4-16"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># The noise scheduler</span></span>
<span id="cb4-17">scheduler <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> LMSDiscreteScheduler(beta_start<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.00085</span>, beta_end<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.012</span>, beta_schedule<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"scaled_linear"</span>, num_train_timesteps<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1000</span>)</span>
<span id="cb4-18">scheduler.set_timesteps(num_inference_steps)</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>The config attributes {'scaling_factor': 0.18215} were passed to AutoencoderKL, but are not expected and will be ignored. Please verify your config.json configuration file.</code></pre>
</div>
</div>
<p>To use these components, we have to first tokenize the prompt. Tokenization is nothing more then transforming each word of the prompt into it’s associated integer according to a “vocabulary”. The “vocabulary” is the mapping of words to integers and is thus generally quite large.</p>
<div class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1">text_input <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> tokenizer(prompt,               <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># the prompt we want to tokenize</span></span>
<span id="cb6-2">                       padding<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"max_length"</span>, <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># pad the tokenized input to the max length</span></span>
<span id="cb6-3">                       return_tensors<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"pt"</span>)  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># return PyTorch tensors</span></span>
<span id="cb6-4">text_input.input_ids</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="12">
<pre><code>tensor([[49406, 16931,   633,   518, 21092,   525,   787,  4370,  3701,  9877,
           320,  3965,   530,   518, 39744, 49407, 49407, 49407, 49407, 49407,
         49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407,
         49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407,
         49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407,
         49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407,
         49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407,
         49407, 49407, 49407, 49407, 49407, 49407, 49407]])</code></pre>
</div>
</div>
<p>Above we see the integers that are associated with each word in our prompt. We can decode the integers back into words and see if it matches our prompt. Let’s have a look at the first 5 tokens:</p>
<div class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb8" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1">[tokenizer.decode(token) <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> token <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> text_input.input_ids[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]][:<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="13">
<pre><code>['&lt;|startoftext|&gt;', 'homer', 'from', 'the', 'simpsons']</code></pre>
</div>
</div>
<p>We see that all capital letters have been removed by the tokenization, and a special token is inserted at the beginning of the prompt. Also, we see the integer <code>49407</code> is being used to pad our input to the maximum length:</p>
<div class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb10" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1">tokenizer.decode(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">49407</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="14">
<pre><code>'&lt;|endoftext|&gt;'</code></pre>
</div>
</div>
<p>Next, we will pass these tokens through the text-encoder to turn each token into an embedding vector. Since we have 77 tokens and the embeddings are of size 768, this will be a tensor of shape <code>[77, 768]</code>.</p>
<div class="cell" data-execution_count="15">
<div class="sourceCode cell-code" id="cb12" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1">text_embeddings <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> text_encoder(text_input.input_ids.to(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"cuda"</span>))[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]</span>
<span id="cb12-2">text_embeddings.shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="15">
<pre><code>torch.Size([1, 77, 768])</code></pre>
</div>
</div>
<p>When generating a completely new image, we start with a fully random noisy latent, so let’s create one:</p>
<div class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb14" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1">torch.manual_seed(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1024</span>)</span>
<span id="cb14-2">latents <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.randn((batch_size,              <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># batch size: 1</span></span>
<span id="cb14-3">                       unet.config.in_channels, <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># input channels of the unet: 4</span></span>
<span id="cb14-4">                       unet.config.sample_size, <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># height dimension of the unet: 64</span></span>
<span id="cb14-5">                       unet.config.sample_size) <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># width dimension of the unet: 64</span></span>
<span id="cb14-6">                     ).to(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"cuda"</span>)               <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># put the tensor on the GPU</span></span>
<span id="cb14-7"></span>
<span id="cb14-8">latents <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> latents <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> scheduler.init_noise_sigma  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># scale the noise</span></span>
<span id="cb14-9"></span>
<span id="cb14-10">latents.shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="16">
<pre><code>torch.Size([1, 4, 64, 64])</code></pre>
</div>
</div>
<p>The latents thus carry 4 channels and are of size 64 by 64. Let’s pass this latent iteratively through the Unet, each time subtracting partly the amount of predicted noise (the output of the Unet)</p>
<div class="cell" data-execution_count="17">
<div class="sourceCode cell-code" id="cb16" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> i, t <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">enumerate</span>(scheduler.timesteps):</span>
<span id="cb16-2">    inputs <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> latents</span>
<span id="cb16-3">    inputs <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> scheduler.scale_model_input(inputs, t)</span>
<span id="cb16-4"></span>
<span id="cb16-5">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># predict the noise </span></span>
<span id="cb16-6">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">with</span> torch.no_grad(): </span>
<span id="cb16-7">        pred <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> unet(inputs, t, encoder_hidden_states<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>text_embeddings).sample</span>
<span id="cb16-8"></span>
<span id="cb16-9">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># update the latents by removing the predicted noise according to the noise schedule</span></span>
<span id="cb16-10">    latents <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> scheduler.step(pred, t, latents).prev_sample</span></code></pre></div>
</div>
<p>Let’s visualize the four channels of this latent representation in grey-scale:</p>
<div class="cell" data-execution_count="18">
<div class="sourceCode cell-code" id="cb17" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1">fig, axs <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> plt.subplots(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>, figsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">16</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>))</span>
<span id="cb17-2"><span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> c <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>):</span>
<span id="cb17-3">    axs[c].imshow(latents[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>][c].cpu(), cmap<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Greys'</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="https://lucasvw.github.io/posts/07_stable_diffusion_code/index_files/figure-html/cell-11-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>To transform the latent representation to full-size images, we can use the decoder of the VAE. Note that when we do that, we move from a tensor of shape <code>[4, 64, 64]</code> to <code>[3, 512, 512]</code>:</p>
<div class="cell" data-execution_count="19">
<div class="sourceCode cell-code" id="cb18" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(latents.shape, vae.decode(latents).sample.shape)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>torch.Size([1, 4, 64, 64]) torch.Size([1, 3, 512, 512])</code></pre>
</div>
</div>
<p>And let’s visualize the result:</p>
<div class="cell" data-execution_count="20">
<div class="sourceCode cell-code" id="cb20" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#scale back according to the VAE paper</span></span>
<span id="cb20-2"><span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">with</span> torch.no_grad(): image <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> vae.decode(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.18215</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> latents).sample</span>
<span id="cb20-3"></span>
<span id="cb20-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># move tensor to numpy</span></span>
<span id="cb20-5">image <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> image[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>].detach().cpu().permute(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>).numpy()</span>
<span id="cb20-6"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># scale the values to 0-255</span></span>
<span id="cb20-7">image <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> ((image <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span>).clip(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">255</span>).<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">round</span>().astype(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"uint8"</span>)</span>
<span id="cb20-8">Image.fromarray(image)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="20">
<p><img src="https://lucasvw.github.io/posts/07_stable_diffusion_code/index_files/figure-html/cell-13-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>Unfortunately, the result looks very bad and especially much worse then our one-liner. The main reason for this, is that the <code>StableDiffusionPipeline</code> is using something called Classifier Free Diffusion Guidance. So let’s have a look at that. But before we do, let’s add two code snippets to transfrom from the latent representation to the full size image representation and back. We will do this a couple of times, so it helps to keep the code a bit cleaner:</p>
<div class="cell" data-execution_count="21">
<div class="sourceCode cell-code" id="cb21" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> latents_to_image(latent):</span>
<span id="cb21-2">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">with</span> torch.no_grad(): </span>
<span id="cb21-3">        image <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> vae.decode(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.18215</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> latent).sample</span>
<span id="cb21-4"></span>
<span id="cb21-5">    image <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> image[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>].detach().cpu().permute(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>).numpy()</span>
<span id="cb21-6">    image <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> ((image <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span>).clip(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">255</span>).<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">round</span>().astype(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"uint8"</span>)</span>
<span id="cb21-7">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> Image.fromarray(image)</span>
<span id="cb21-8">    </span>
<span id="cb21-9"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> image_to_latent(input_im):</span>
<span id="cb21-10">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">with</span> torch.no_grad():</span>
<span id="cb21-11">        latent <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> vae.encode(torch.Tensor(np.transpose(np.array(input_im) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">255.</span>, (<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>))).unsqueeze(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>).to(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'cuda'</span>)<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb21-12">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.18215</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> (latent).latent_dist.sample()</span></code></pre></div>
</div>
<section id="classifier-free-diffusion-guidance" class="level2">
<h2 class="anchored" data-anchor-id="classifier-free-diffusion-guidance">Classifier Free Diffusion Guidance</h2>
<p>Classifier Free Guidance refers to a technique in which two images are being constructed at the same time from the same latent. One of the images is being reconstructed based on the specified prompt (conditional generation), the other image is being generated by an empty prompt (unconditional generation). By mixing the two images in the process according to a parameter (called the guidance-scale) the generated image for the prompt is going to look much better:</p>
<div class="cell" data-execution_count="22">
<div class="sourceCode cell-code" id="cb22" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1">torch.manual_seed(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3016</span>)</span>
<span id="cb22-2"></span>
<span id="cb22-3">cond_input <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> tokenizer(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Homer from the Simpsons on his roadbike climbing a mountain in the Pyrenees"</span>, padding<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"max_length"</span>, return_tensors<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"pt"</span>) </span>
<span id="cb22-4">cond_embeddings <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> text_encoder(cond_input.input_ids.to(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"cuda"</span>))[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]</span>
<span id="cb22-5"></span>
<span id="cb22-6"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create embeddings for the unconditioned process</span></span>
<span id="cb22-7">uncond_input <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> tokenizer(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">""</span>, padding<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"max_length"</span>, return_tensors<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"pt"</span>) </span>
<span id="cb22-8">uncond_embeddings <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> text_encoder(uncond_input.input_ids.to(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"cuda"</span>))[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]</span>
<span id="cb22-9"></span>
<span id="cb22-10"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Concatenate the embeddings</span></span>
<span id="cb22-11">embeddings <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.cat([cond_embeddings, uncond_embeddings])</span>
<span id="cb22-12"></span>
<span id="cb22-13">guidance_scale <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">7.5</span></span>
<span id="cb22-14"></span>
<span id="cb22-15"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create a "fresh" random latent to start with</span></span>
<span id="cb22-16">latents <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.randn((batch_size, unet.config.in_channels, unet.config.sample_size, unet.config.sample_size)).to(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"cuda"</span>)               </span>
<span id="cb22-17">latents <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> latents <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> scheduler.init_noise_sigma</span>
<span id="cb22-18"></span>
<span id="cb22-19"><span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> i, t <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">enumerate</span>(scheduler.timesteps):</span>
<span id="cb22-20">    inputs <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.cat([latents, latents]) <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># concatenate the latents</span></span>
<span id="cb22-21">    inputs <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> scheduler.scale_model_input(inputs, t)</span>
<span id="cb22-22"></span>
<span id="cb22-23">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># predict the noise </span></span>
<span id="cb22-24">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">with</span> torch.no_grad(): </span>
<span id="cb22-25">        pred <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> unet(inputs, t, encoder_hidden_states<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>embeddings).sample</span>
<span id="cb22-26">    </span>
<span id="cb22-27">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># pull both images apart again</span></span>
<span id="cb22-28">    pred_cond, pred_uncond <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pred.chunk(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>)</span>
<span id="cb22-29">    </span>
<span id="cb22-30">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># mix the results according to the guidance scale parameter</span></span>
<span id="cb22-31">    pred <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pred_uncond <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> guidance_scale <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> (pred_cond <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> pred_uncond)</span>
<span id="cb22-32"></span>
<span id="cb22-33">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># update the latents by removing the predicted noise according to the noise schedule</span></span>
<span id="cb22-34">    latents <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> scheduler.step(pred, t, latents).prev_sample</span>
<span id="cb22-35">    </span>
<span id="cb22-36">latents_to_image(latents)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="22">
<p><img src="https://lucasvw.github.io/posts/07_stable_diffusion_code/index_files/figure-html/cell-15-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>Much better! As you can see, Classifier Free Guidance is a simple technique but it works very well. This morning (03-07-2023) I saw a tweet that introduced the same concept to the world of Large Language Models (LLMs):</p>
<p></p><div id="tweet-49292"></div><script>tweet={"url":"https:\/\/twitter.com\/_akhaliq\/status\/1675676002213584897","author_name":"AK","author_url":"https:\/\/twitter.com\/_akhaliq","html":"\u003Cblockquote class=\"twitter-tweet\" align=\"center\"\u003E\u003Cp lang=\"en\" dir=\"ltr\"\u003EStay on topic with Classifier-Free Guidance\u003Cbr\u003E\u003Cbr\u003Epaper page: \u003Ca href=\"https:\/\/t.co\/yYpAXON3ep\"\u003Ehttps:\/\/t.co\/yYpAXON3ep\u003C\/a\u003E\u003Cbr\u003E\u003Cbr\u003EClassifier-Free Guidance (CFG) has recently emerged in text-to-image generation as a lightweight technique to encourage prompt-adherence in generations. In this work, we demonstrate that CFG can be… \u003Ca href=\"https:\/\/t.co\/qCZHWKw7NO\"\u003Epic.twitter.com\/qCZHWKw7NO\u003C\/a\u003E\u003C\/p\u003E&mdash; AK (@_akhaliq) \u003Ca href=\"https:\/\/twitter.com\/_akhaliq\/status\/1675676002213584897?ref_src=twsrc%5Etfw\"\u003EJuly 3, 2023\u003C\/a\u003E\u003C\/blockquote\u003E\n\u003Cscript async src=\"https:\/\/platform.twitter.com\/widgets.js\" charset=\"utf-8\"\u003E\u003C\/script\u003E\n","width":550,"height":null,"type":"rich","cache_age":"3153600000","provider_name":"Twitter","provider_url":"https:\/\/twitter.com","version":"1.0"};document.getElementById("tweet-49292").innerHTML = tweet["html"];</script><p></p>
</section>
<section id="negative-prompt" class="level2">
<h2 class="anchored" data-anchor-id="negative-prompt">Negative Prompt</h2>
<p>As mentioned, the unconditional image with Classifier Free Guidance is created from an empty prompt. It turns out that we can use the prompt of this second image as a so-called negative prompt. If there are certain elements we don’t want to see in our image, we can specify it in this prompt.</p>
<p>We can see this by rewriting the Classifier Free Guidance equation:</p>
<p><img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Balign%7D%0Ap%20&amp;=%20p_%7Buc%7D%20+%20g%20(p_%7Bc%7D%20-%20p_%7Buc%7D)%20%5C%5C%0Ap%20&amp;=%20g%20p_%7Bc%7D%20+%20(1%20-%20g)%20p_%7Buc%7D%20%5C%5C%0A%5Cend%7Balign%7D"></p>
<p>So with a guidance scale value larger than 1, the unconditional prediction <img src="https://latex.codecogs.com/png.latex?p_%7Buc%7D"> is being subtracted from the conditional prediction <img src="https://latex.codecogs.com/png.latex?p_c">, which has the effect of removing the concept from the conditional image.</p>
<p>An example of Homer Simpson eating lunch:</p>
<div class="cell" data-execution_count="79">
<div class="sourceCode cell-code" id="cb23" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1">cond_input <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> tokenizer(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Homer Simpson eating lunch"</span>, padding<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"max_length"</span>, return_tensors<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"pt"</span>) </span>
<span id="cb23-2">cond_embeddings <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> text_encoder(cond_input.input_ids.to(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"cuda"</span>))[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]</span>
<span id="cb23-3"></span>
<span id="cb23-4">uncond_input <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> tokenizer(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">""</span>, padding<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"max_length"</span>, return_tensors<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"pt"</span>) </span>
<span id="cb23-5">uncond_embeddings <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> text_encoder(uncond_input.input_ids.to(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"cuda"</span>))[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]</span></code></pre></div>
</div>
<div class="cell" data-execution_count="80">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb24" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1">torch.manual_seed(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">105</span>)</span>
<span id="cb24-2"></span>
<span id="cb24-3">embeddings <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.cat([cond_embeddings, uncond_embeddings])</span>
<span id="cb24-4"></span>
<span id="cb24-5">guidance_scale <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">7.5</span></span>
<span id="cb24-6"></span>
<span id="cb24-7">latents <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.randn((batch_size, unet.config.in_channels, unet.config.sample_size, unet.config.sample_size)).to(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"cuda"</span>)               </span>
<span id="cb24-8">latents <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> latents <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> scheduler.init_noise_sigma</span>
<span id="cb24-9"></span>
<span id="cb24-10"><span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> i, t <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">enumerate</span>(scheduler.timesteps):</span>
<span id="cb24-11">    inputs <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.cat([latents, latents]) <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># concatenate the latents</span></span>
<span id="cb24-12">    inputs <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> scheduler.scale_model_input(inputs, t)</span>
<span id="cb24-13"></span>
<span id="cb24-14">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">with</span> torch.no_grad(): </span>
<span id="cb24-15">        pred <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> unet(inputs, t, encoder_hidden_states<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>embeddings).sample</span>
<span id="cb24-16">    </span>
<span id="cb24-17">    pred_cond, pred_uncond <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pred.chunk(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>)</span>
<span id="cb24-18">    </span>
<span id="cb24-19">    pred <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pred_uncond <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> guidance_scale <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> (pred_cond <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> pred_uncond)</span>
<span id="cb24-20"></span>
<span id="cb24-21">    latents <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> scheduler.step(pred, t, latents).prev_sample</span>
<span id="cb24-22"></span>
<span id="cb24-23">latents_to_image(latents)</span></code></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="80">
<p><img src="https://lucasvw.github.io/posts/07_stable_diffusion_code/index_files/figure-html/cell-17-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>And removing the blue chair by using a negative prompt:</p>
<div class="cell" data-execution_count="81">
<div class="sourceCode cell-code" id="cb25" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1">uncond_input <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> tokenizer(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"blue chair"</span>, padding<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"max_length"</span>, return_tensors<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"pt"</span>) </span>
<span id="cb25-2">uncond_embeddings <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> text_encoder(uncond_input.input_ids.to(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"cuda"</span>))[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]</span></code></pre></div>
</div>
<div class="cell" data-execution_count="82">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb26" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1">torch.manual_seed(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">105</span>)</span>
<span id="cb26-2"></span>
<span id="cb26-3">embeddings <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.cat([cond_embeddings, uncond_embeddings])</span>
<span id="cb26-4"></span>
<span id="cb26-5">guidance_scale <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">7.5</span></span>
<span id="cb26-6"></span>
<span id="cb26-7">latents <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.randn((batch_size, unet.config.in_channels, unet.config.sample_size, unet.config.sample_size)).to(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"cuda"</span>)               </span>
<span id="cb26-8">latents <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> latents <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> scheduler.init_noise_sigma</span>
<span id="cb26-9"></span>
<span id="cb26-10"><span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> i, t <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">enumerate</span>(scheduler.timesteps):</span>
<span id="cb26-11">    inputs <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.cat([latents, latents]) <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># concatenate the latents</span></span>
<span id="cb26-12">    inputs <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> scheduler.scale_model_input(inputs, t)</span>
<span id="cb26-13"></span>
<span id="cb26-14">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">with</span> torch.no_grad(): </span>
<span id="cb26-15">        pred <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> unet(inputs, t, encoder_hidden_states<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>embeddings).sample</span>
<span id="cb26-16">    </span>
<span id="cb26-17">    pred_cond, pred_uncond <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pred.chunk(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>)</span>
<span id="cb26-18">    </span>
<span id="cb26-19">    pred <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pred_uncond <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> guidance_scale <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> (pred_cond <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> pred_uncond)</span>
<span id="cb26-20"></span>
<span id="cb26-21">    latents <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> scheduler.step(pred, t, latents).prev_sample</span>
<span id="cb26-22"></span>
<span id="cb26-23">image <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> latents_to_image(latents)</span>
<span id="cb26-24">image</span></code></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="82">
<p><img src="https://lucasvw.github.io/posts/07_stable_diffusion_code/index_files/figure-html/cell-19-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>And gone is the blue chair! I must admit that this doesn’t always work as great as in this example, in fact I had to try out quite a lot of prompts in combination with negative prompts to find a good example for this post..</p>
</section>
<section id="image-to-image-generation" class="level2">
<h2 class="anchored" data-anchor-id="image-to-image-generation">Image-to-image generation</h2>
<p>Image-to-image generation is another super interesting process, in which we use both a prompt and an image to guide the generation process. This comes in handy, if for example we want to create a variant of an image we already have. Let’s say we have an awesome image of Homer eating a burger, and we want to have a similar image but instead we want Marge to eat the burger, or we want Homer to eat a slice of pizza instead. We can then feed both the correct promt as well as the already existing image to guide the image generation process even more.</p>
<p>The way this works, is by not starting with a completely random latent, but instead build a noisy latent of our existing image.</p>
<p>Let’s start with the image above and add some noise to it, for example by adding the noise for level 15 (we have 50 noise levels in total, so level 15 means that we still have 35 denoising steps to go):</p>
<div class="cell" data-execution_count="167">
<div class="sourceCode cell-code" id="cb27" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1">latent <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> image_to_latent(image)</span>
<span id="cb27-2">noise_latent <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.randn_like(latent)</span>
<span id="cb27-3"></span>
<span id="cb27-4">sampling_step <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">15</span></span>
<span id="cb27-5">noised_latent <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> scheduler.add_noise(latent, noise_latent, timesteps<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>torch.tensor([scheduler.timesteps[sampling_step]]))</span>
<span id="cb27-6"></span>
<span id="cb27-7">latents_to_pil(noised_latent)[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="167">
<p><img src="https://lucasvw.github.io/posts/07_stable_diffusion_code/index_files/figure-html/cell-20-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>If you squint with your eyes you can already see some structure, in the middle there is some yellow blob sitting around (eating lunch..). Let’s take this noisy latent, and do the remaining 35 denoising steps with a different prompt:</p>
<div class="cell" data-execution_count="175">
<div class="sourceCode cell-code" id="cb28" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1">torch.manual_seed(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">105</span>)</span>
<span id="cb28-2"></span>
<span id="cb28-3">cond_input <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> tokenizer(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Homer Simpson eating Hot Pot"</span>, padding<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"max_length"</span>, return_tensors<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"pt"</span>) </span>
<span id="cb28-4">cond_embeddings <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> text_encoder(cond_input.input_ids.to(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"cuda"</span>))[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]</span>
<span id="cb28-5"></span>
<span id="cb28-6">uncond_input <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> tokenizer(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">""</span>, padding<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"max_length"</span>, return_tensors<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"pt"</span>) </span>
<span id="cb28-7">uncond_embeddings <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> text_encoder(uncond_input.input_ids.to(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"cuda"</span>))[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]</span>
<span id="cb28-8"></span>
<span id="cb28-9">embeddings <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.cat([cond_embeddings, uncond_embeddings])</span>
<span id="cb28-10"></span>
<span id="cb28-11">guidance_scale <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">7.5</span></span>
<span id="cb28-12"></span>
<span id="cb28-13"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># We start with the noised_latent coming from the image, defined above</span></span>
<span id="cb28-14">latents <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> noised_latent</span>
<span id="cb28-15"></span>
<span id="cb28-16"><span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> i, t <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">enumerate</span>(scheduler.timesteps):</span>
<span id="cb28-17">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># we only do the steps starting from the specified level</span></span>
<span id="cb28-18">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> i <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;=</span> sampling_step:</span>
<span id="cb28-19">        </span>
<span id="cb28-20">        inputs <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.cat([latents, latents])</span>
<span id="cb28-21">        inputs <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> scheduler.scale_model_input(inputs, t)</span>
<span id="cb28-22"></span>
<span id="cb28-23">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">with</span> torch.no_grad(): </span>
<span id="cb28-24">            pred <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> unet(inputs, t, encoder_hidden_states<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>embeddings).sample</span>
<span id="cb28-25"></span>
<span id="cb28-26">        pred_cond, pred_uncond <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pred.chunk(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>)</span>
<span id="cb28-27">        pred <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pred_uncond <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> guidance_scale <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> (pred_cond <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> pred_uncond)</span>
<span id="cb28-28"></span>
<span id="cb28-29">        latents <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> scheduler.step(pred, t, latents).prev_sample</span>
<span id="cb28-30">    </span>
<span id="cb28-31">latents_to_image(latents)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="175">
<p><img src="https://lucasvw.github.io/posts/07_stable_diffusion_code/index_files/figure-html/cell-21-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>This image is very similar to what we started with. Color scheme, composition and camera angle are all the same. At the same time, the prompt is also reflected by a change of dishes on the table.</p>
<p>And that’s it, that’s image-to-image generation. As you can see, it’s nothing deeply complicated, it’s just a smart way to re-use the components we have already seen.</p>
<p>I hope this blog post shows how the components that are introduced in the previous <a href="https://lucasvw.github.io/posts/06_stable_diffusion_basics/">post</a>, translate to code. The examples shown here, only touch upon what can be achieved. In fact, the lessons upon which this post is based show a lot more interesting concepts such as textual inversion. If you are interested, have a look <a href="https://course.fast.ai">here</a></p>


</section>

 ]]></description>
  <category>Generative</category>
  <category>Stable Diffusion</category>
  <category>Diffusers</category>
  <category>Code</category>
  <guid>https://lucasvw.github.io/posts/07_stable_diffusion_code/index.html</guid>
  <pubDate>Mon, 03 Jul 2023 00:00:00 GMT</pubDate>
  <media:content url="https://lucasvw.github.io/posts/07_stable_diffusion_code/image.png" medium="image" type="image/png" height="142" width="144"/>
</item>
<item>
  <title>Introduction to Stable Diffusion - Concepts</title>
  <dc:creator>Lucas van Walstijn</dc:creator>
  <link>https://lucasvw.github.io/posts/06_stable_diffusion_basics/index.html</link>
  <description><![CDATA[ 




<p>Stable Diffusion, a generative deep learning algorithm developed in 2022, is capable of creating images from prompts. For example, when presented the prompt: <strong>A group of people having lunch on the moon</strong>, the algorithm creates the following image:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://lucasvw.github.io/posts/06_stable_diffusion_basics/image.png" class="img-fluid figure-img"></p>
</figure>
</div>
<p>And although this image isn’t perfect, it’s pretty amazing that it took less then 30 seconds to create this image. The algorithm “imagined” that people on the moon should be wearing space suits, and that lunch is generally eaten in a sitting position and around a table. Also, the surroundings look indeed pretty moonish. Not bad at all!</p>
<p>In this post, we will have a look at the main components involved in creating this image, and follows largely the steps of <a href="https://course.fast.ai/Lessons/lesson9.html">Lesson 9 of Deep Learning for Coders</a>.</p>
<section id="intuition" class="level2">
<h2 class="anchored" data-anchor-id="intuition">Intuition</h2>
<p>Consider some kind of black box system that takes some input data, and based on it creates some output data. Let’s say, it takes an image of a handwritten digit as input, and outputs the probability that the image is indeed a hand written digit. Visually something like this:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://lucasvw.github.io/posts/06_stable_diffusion_basics/intuition-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
<p>In statistics, we would call this a probability density function. It’s a function that takes data as input, and gives the probability that</p>
<ul>
<li>if the input data is coming indeed from the distribution,</li>
<li>what’s the probability that we see this data?</li>
</ul>
<p>Applied to our use-case: if the presented image is indeed from the distribution (of images) that represent hand written digits, what’s the probability that we observe the presented image?</p>
<p>With such a system, we could start with an image made up of pure noise and iteratively do:</p>
<ol type="1">
<li>get the probability <img src="https://latex.codecogs.com/png.latex?p_0"> of the image being a handwritten digit from the black box system</li>
<li>change the value of one of the pixels at random</li>
<li>get the new probability <img src="https://latex.codecogs.com/png.latex?p_1"> whether the image is a handwritten digit from the black box system</li>
<li>when <img src="https://latex.codecogs.com/png.latex?p_1%20%3E%20p_0"> update the image with the changed pixel value</li>
</ol>
<p>When following this procedure long enough and thus updating pixel for pixel, we would gradually change all the values of our pixels of our image, until eventually it will start to resemble a handwritten digit.</p>
<p>In principle, this is the simple intuition behind stable diffusion.</p>
</section>
<section id="the-main-component-unet" class="level2">
<h2 class="anchored" data-anchor-id="the-main-component-unet">The main component: Unet</h2>
<p>So how are we going to create this system that will return the probability that an image is depicting a handwritten digit? Let’s try to create a model, that will do so. To get the training data, we need lots of images that depict handwritten digits. Something like this:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://lucasvw.github.io/posts/06_stable_diffusion_basics/mnist.png" class="img-fluid figure-img"></p>
</figure>
</div>
<p>Since these images represent actual hand-written digits, the system will need to output a probability close to 1 for these images. But how do we get images that “somewhat” or “rarely” represent handwritten digits and are associated with lower probability values? We somehow have to “crappify” these existing images. We can do this by using these same images and sprinkle them with different amounts of noise. The more noise we add, the less the image will resemble a handwritten digit. Visually:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://lucasvw.github.io/posts/06_stable_diffusion_basics/intuition-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
<p>Now we can train a network which we feed the <em>noisified images</em> as input and use the <em>noise image</em> as label. So instead of predicting the probability that an image depicts a handwritten digit, the model will predict the noise. By using a simple MSE loss on the actual noise (labels) and the predictions the model will learn how to predict the noise from looking at a noisified images.</p>
<p>The idea behind this model is that once this model is trained, we could run inference on some random noise. The model will give us a prediction of all the noise in the image, which when removed from the input, renders an image of a digit.</p>
<p>It turns out that this process works much better if, instead of removing all the noise that was predicted by the model at once, we just remove a little bit of the noise that was predicted. This way, we end up with an image which is just a bit less noisy then what we started with. We then feed this less noisy image again into our network, and thus iteratively remove more and more noise from the image, until after a certain amount of steps (50 for example) we end-up with an image that is free of noise.</p>
<p>One model architecture that is takes images as input and also outputs images is called a Unet and forms the first component of our Stable Diffusion system:</p>
<table class="table">
<colgroup>
<col style="width: 10%">
<col style="width: 25%">
<col style="width: 25%">
</colgroup>
<thead>
<tr class="header">
<th>Component</th>
<th style="text-align: left;">Inputs</th>
<th style="text-align: left;">Outputs</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Unet</td>
<td style="text-align: left;">Noisy images</td>
<td style="text-align: left;">Noise</td>
</tr>
</tbody>
</table>
</section>
<section id="compression-variational-autoencoder" class="level2">
<h2 class="anchored" data-anchor-id="compression-variational-autoencoder">Compression: Variational Autoencoder</h2>
<p>When working with images in neural networks we often reduce the resolution of images or use smaller patches of the original image to make sure everything fits on the GPU. With stable diffusion, we naturally want to output images of high resolution, so we either need very large GPUs, or instead we use a compression trick by making use of a Variational Autoencoder (VAE).</p>
<p>A VAE is a network architecture having an encoder and a decoder. In the encoder the image input is being transformed through a series of convolutional layers into a compressed representation, the latent. In the decoder this compressed latent is passed through a series of layers that are trying to reconstruct the original image. Visually:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://lucasvw.github.io/posts/06_stable_diffusion_basics/intuition-3.png" class="img-fluid figure-img"></p>
</figure>
</div>
<p>This might look like a boring network architecture at first. But it’s actually a very neat way to compress things: We can feed this model all the different noisified images mentioned earlier, and use an MSE loss on the inputs and outputs. This will train the model to create compressed representations of our images (the latents) that can be used by the decoder to recreate the original image. This means that the latent representation carries close to the same amount of “information” as our full-size images.</p>
<p>With this, we can now train the previously discussed Unet on all the latents instead of the full size images!</p>
<p>During inference the combined architecture looks like this: we run any input first through the encoder returning a highly compressed version of our input (i.e.&nbsp;the latents). We then run it through the Unet, which will output a latent representation of the noise. If we (partly) subtract the noise latent from the noisy image latent, we end up with a latent representation of our image which is a bit less noisy then what we started with. Finally, to move from latent representation to full-size images, we can use the decoder of the VAE. Visually:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://lucasvw.github.io/posts/06_stable_diffusion_basics/intuition-4.png" class="img-fluid figure-img"></p>
</figure>
</div>
<p>To summarize:</p>
<table class="table">
<colgroup>
<col style="width: 10%">
<col style="width: 25%">
<col style="width: 25%">
</colgroup>
<thead>
<tr class="header">
<th>Component</th>
<th style="text-align: left;">Inputs</th>
<th style="text-align: left;">Outputs</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>VAE encoder</td>
<td style="text-align: left;">Noisy image</td>
<td style="text-align: left;">Noisy image latents</td>
</tr>
<tr class="even">
<td>Unet</td>
<td style="text-align: left;">Noisy image latents</td>
<td style="text-align: left;">Noise latents</td>
</tr>
<tr class="odd">
<td>VAE decoder</td>
<td style="text-align: left;">Noise latents</td>
<td style="text-align: left;">Noise</td>
</tr>
</tbody>
</table>
</section>
<section id="prompting-clip" class="level2">
<h2 class="anchored" data-anchor-id="prompting-clip">Prompting: CLIP</h2>
<p>So how can we create prompting? Let’s start simple and imagine we just want to specify which handwritten digit we would like to generate, so any number between 0 and 9. We could do this by training the Unet not only on the noisy image (input) and noise (output), but instead also give it a representation of the digit we sprinkled the noise on as input. The most generic way to do this, would be to create a one-hot encoded representation of the digit, visually:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://lucasvw.github.io/posts/06_stable_diffusion_basics/intuition-5.png" class="img-fluid figure-img"></p>
</figure>
</div>
<p>To create an image depicting the digit “three” from pure noise, we would then start with a random noise latent and feed it together with the one-hot encoded representation of the digit into the Unet. This way, the Unet is “guided” to create an image of digit “three” and not just any image, visually:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://lucasvw.github.io/posts/06_stable_diffusion_basics/intuition-5-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
<p>To continue, how are we going to scale this for <em>any</em> text prompt besides our 10 digits? We can’t possibly create a one-hot encoding of any possible prompt, that would make our vector infinitely large. Instead, we want to compress the encoding in some finite, high dimensional space, e.g.&nbsp;we want to create an embedding encoding of our prompt.</p>
<p>To create these embeddings, we first of all need again lots of data. For example by capturing a lot of images from the internet, these image generally have a textual description in the HTML tag.</p>
<p>We can feed the text and images into two separate encoders. These encoders take the text and image respectively and output a vector. Next, we can align the vector representations in a matrix and take the dot-product between them. We want the text and image vectors of the same “object” to align, this means their dot-product should be large. Also, we want the vectors of different objects to not align, so their dot-product should be small. Visually:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://lucasvw.github.io/posts/06_stable_diffusion_basics/intuition-6.png" class="img-fluid figure-img"></p>
</figure>
</div>
<p>A loss function that does exactly this, is called the Contrastive Loss. And the model described here is called Contrastive Language Image Pre-training (CLIP).</p>
<p>During inference, we can use the trained text-encoder and apply it to the prompt. The outputted embedding can then be used as the encoding we feed into our Unet in combination with the noisy image latent.</p>
<p>To summarize:</p>
<table class="table">
<colgroup>
<col style="width: 10%">
<col style="width: 25%">
<col style="width: 25%">
</colgroup>
<thead>
<tr class="header">
<th>Component</th>
<th style="text-align: left;">Inputs</th>
<th style="text-align: left;">Outputs</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>CLIP text encoder</td>
<td style="text-align: left;">Prompt</td>
<td style="text-align: left;">Embedding</td>
</tr>
<tr class="even">
<td>VAE encoder</td>
<td style="text-align: left;">Noisy image</td>
<td style="text-align: left;">Noisy image latents</td>
</tr>
<tr class="odd">
<td>Unet</td>
<td style="text-align: left;">Noisy image latents + Prompt embedding</td>
<td style="text-align: left;">Noise latents</td>
</tr>
<tr class="even">
<td>VAE decoder</td>
<td style="text-align: left;">Noise latents</td>
<td style="text-align: left;">Noise</td>
</tr>
</tbody>
</table>
</section>
<section id="noise-scheduler" class="level2">
<h2 class="anchored" data-anchor-id="noise-scheduler">Noise scheduler</h2>
<p>Above it was stated, that “different” amounts of noise are sprinkled on our images during training, and during inference “some” amount of noise is being subtracted from the image. In the next post, which will be a “code” version of this post, we will see more how this exactly works, but let’s introduce one more concept here:</p>
<p>To formalize the amounts of noise we will use something called a noise schedule, which maps an integer value (called the timestep <img src="https://latex.codecogs.com/png.latex?t">) to an amount of noise we will add to our image. This noise schedule is a monotonically decreasing function of <img src="https://latex.codecogs.com/png.latex?t">, so large values of <img src="https://latex.codecogs.com/png.latex?t"> will add a small amount of noise and small values of <img src="https://latex.codecogs.com/png.latex?t"> add a large amount of noise. A typical noise schedule looks something like this:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://lucasvw.github.io/posts/06_stable_diffusion_basics/noise-schedule.png" class="img-fluid figure-img"></p>
</figure>
</div>
<p>With this noise schedule, we can pick different amounts of noise during training and add it to the images in the batch. Additionally, we will feed the noise parameter to the Unet, so that it knows how much noise was added to the image. This sould make it easier for the model to reconstruct the noise.</p>
<p>To summarize:</p>
<table class="table">
<colgroup>
<col style="width: 10%">
<col style="width: 25%">
<col style="width: 25%">
</colgroup>
<thead>
<tr class="header">
<th>Component</th>
<th style="text-align: left;">Inputs</th>
<th style="text-align: left;">Outputs</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>CLIP text encoder</td>
<td style="text-align: left;">Prompt</td>
<td style="text-align: left;">Embedding</td>
</tr>
<tr class="even">
<td>VAE encoder</td>
<td style="text-align: left;">Noisy image</td>
<td style="text-align: left;">Noisy image latents</td>
</tr>
<tr class="odd">
<td>Unet</td>
<td style="text-align: left;">Noisy image latents + Prompt embedding + Noise level</td>
<td style="text-align: left;">Noise latents</td>
</tr>
<tr class="even">
<td>VAE decoder</td>
<td style="text-align: left;">Noise latents</td>
<td style="text-align: left;">Noise</td>
</tr>
</tbody>
</table>
<p>That’s it for now! If you came this far, I hope you enjoyed it. For me, it helped a lot in my understanding by writing all this down. In the next blog post, we will have a look at how these concepts translate into code by making use of HuggingFace libraries such as <code>diffusers</code> and <code>transformers</code></p>


</section>

 ]]></description>
  <category>Generative</category>
  <category>Stable Diffusion</category>
  <category>Diffusers</category>
  <category>Concepts</category>
  <guid>https://lucasvw.github.io/posts/06_stable_diffusion_basics/index.html</guid>
  <pubDate>Sat, 18 Mar 2023 00:00:00 GMT</pubDate>
  <media:content url="https://lucasvw.github.io/posts/06_stable_diffusion_basics/image.png" medium="image" type="image/png" height="131" width="144"/>
</item>
<item>
  <title>Cross entropy any which way</title>
  <dc:creator>Lucas van Walstijn</dc:creator>
  <link>https://lucasvw.github.io/posts/05_crossentropy/index.html</link>
  <description><![CDATA[ 




<p>Cross entropy is one of the most commonly used loss functions. In this post, we will have a look at how it works, and compute it in a couple of different ways.</p>
<p>Consider a network that is build for image classification. During the forward pass, images are passed into the network and the network processes the data layer by layer, until evenually some final activations are being returned by the model. These final activations are called “logits” and represent the unnormalized predictions of our model.</p>
<p>Since we generally use mini-batches during training, these logits are of shape <code>[bs, num_classes]</code></p>
<div class="cell" data-execution_count="20">
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> torch</span>
<span id="cb1-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> torch.nn.functional <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> F</span>
<span id="cb1-3"></span>
<span id="cb1-4">g <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.manual_seed(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">42</span>) <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># use a generator for reproducability</span></span>
<span id="cb1-5"></span>
<span id="cb1-6">bs <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">32</span> <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># batch size of 32</span></span>
<span id="cb1-7">num_classes <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span> <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># image classification with 3 different classes</span></span>
<span id="cb1-8"></span>
<span id="cb1-9">logits <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.randn(size<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(bs, num_classes), generator<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>g) <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># size: [32,3]</span></span>
<span id="cb1-10"></span>
<span id="cb1-11">logits[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>:<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>] <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># show the logits for the first couple of samples</span></span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="20">
<pre><code>tensor([[ 1.9269,  1.4873,  0.9007],
        [-2.1055,  0.6784, -1.2345],
        [-0.0431, -1.6047, -0.7521],
        [ 1.6487, -0.3925, -1.4036]])</code></pre>
</div>
</div>
<p>Each row of this tensor represents the unnormalized predictions for each of our samples in the batch. We can normalize these predictions by applying a softmax. The softmax function does two things:</p>
<ol type="1">
<li>make all our logits positive, by applying the exponential function, <a href="https://www.wolframalpha.com/input?i=exp%28x%29" target="_blank">wolfram alpha reference</a></li>
<li>divide each value of the exponentiated logits by the sum over all the classes</li>
</ol>
<p>This makes sure that we can treat the output of this as probabilities, because:</p>
<ol type="1">
<li>all individual predictions will be between 0 and 1</li>
<li>the predictions will sum to 1</li>
</ol>
<p>Specifically:</p>
<div class="cell" data-execution_count="21">
<div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Unnormalized predictions for our first sample (3 classes)</span></span>
<span id="cb3-2">logits[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="21">
<pre><code>tensor([1.9269, 1.4873, 0.9007])</code></pre>
</div>
</div>
<div class="cell" data-execution_count="22">
<div class="sourceCode cell-code" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Exponentiated predictions, making them all positive</span></span>
<span id="cb5-2">exp_logits <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> logits[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>].exp()</span>
<span id="cb5-3">exp_logits</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="22">
<pre><code>tensor([6.8683, 4.4251, 2.4614])</code></pre>
</div>
</div>
<div class="cell" data-execution_count="25">
<div class="sourceCode cell-code" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Turn these values into probabilities by dividing by the sum</span></span>
<span id="cb7-2">probs <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> exp_logits <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> exp_logits.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">sum</span>()</span>
<span id="cb7-3"></span>
<span id="cb7-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># verify that the sum of the probabilities sum to 1</span></span>
<span id="cb7-5"><span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">assert</span> torch.allclose(probs.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">sum</span>(), torch.tensor(<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.</span>))</span>
<span id="cb7-6"></span>
<span id="cb7-7">probs</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="25">
<pre><code>tensor([0.4993, 0.3217, 0.1789])</code></pre>
</div>
</div>
<p>So, let’s create a softmax function that does this for a whole batch:</p>
<div class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb9" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> softmax(logits):</span>
<span id="cb9-2">    exp_logits <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> logits.exp() <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># shape: [32, 3]</span></span>
<span id="cb9-3">    exp_logits_sum <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> exp_logits.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">sum</span>(dim<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, keepdim<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>) <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># shape: [32, 1]</span></span>
<span id="cb9-4">    </span>
<span id="cb9-5">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Note: this get's correctly broadcasted, since the exp_logits_sum will </span></span>
<span id="cb9-6">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># expand to [32, 3], so each value in exp_logits gets divided by the sum over its row</span></span>
<span id="cb9-7">    probs <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> exp_logits <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> exp_logits_sum <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># shape: [32, 3]</span></span>
<span id="cb9-8">    </span>
<span id="cb9-9">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> probs </span>
<span id="cb9-10"></span>
<span id="cb9-11">probs <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> softmax(logits)</span>
<span id="cb9-12">probs[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>:<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="7">
<pre><code>tensor([[0.4993, 0.3217, 0.1789],
        [0.0511, 0.8268, 0.1221],
        [0.5876, 0.1233, 0.2891],
        [0.8495, 0.1103, 0.0401]])</code></pre>
</div>
</div>
<p>Next, we want to compute the loss for which also need our <code>labels</code>. These labels represent the ground truth class for each of our samples in the batch. Since we have 3 classes they will be between 0 and 3 (e.g.&nbsp;either 0, 1 or 2)</p>
<div class="cell" data-execution_count="26">
<div class="sourceCode cell-code" id="cb11" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1">g <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.manual_seed(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">42</span>) <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># use a generator for reproducability</span></span>
<span id="cb11-2"></span>
<span id="cb11-3">labels <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.randint(low<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, high<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>, size<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">32</span>,), generator<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>g)</span>
<span id="cb11-4">labels</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="26">
<pre><code>tensor([0, 2, 1, 1, 0, 2, 1, 2, 1, 2, 1, 1, 2, 0, 0, 1, 2, 1, 0, 1, 1, 2, 1, 2,
        2, 1, 2, 0, 1, 1, 0, 0])</code></pre>
</div>
</div>
<p>For classification we use the Negative Log Likelihood loss function, which is defined as such:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Ctextrm%7BNLL%7D%20=%20-%20%5Csum_%7Bi%7D%7Bq_i%20*%20%5Clog(p_i)%7D%0A"></p>
<p>with <img src="https://latex.codecogs.com/png.latex?i"> being the index that moves along the classes (3 in our example) and <img src="https://latex.codecogs.com/png.latex?q_i"> being the probability that the ground truth label is class <img src="https://latex.codecogs.com/png.latex?i"> (this is a somewhat strange formulation, since this probability is either 1 (for the correct class) or 0 (for all the non-correct classes)). Finally, <img src="https://latex.codecogs.com/png.latex?p_i"> is the probability that the model associated to class <img src="https://latex.codecogs.com/png.latex?i">.</p>
<p>For the very first row of our <code>probs</code> (<code>[0.4993, 0.3217, 0.1789]</code>) and our first label (<code>0</code>) we thus get:</p>
<p><img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Balign%7D%0A%5Ctextrm%7BNLL%7D%20&amp;=%20-%20(%20(1%20%5Ccdot%20%5Clog(0.4993))%20+%20(0%20%5Ccdot%20%5Clog(0.3217))%20+%20(1%20%5Ccdot%20%5Clog(0.1789))%20)%20%5C%5C%0A%5Ctextrm%7BNLL%7D%20&amp;=%20-%20(%20(1%20%5Ccdot%20%5Clog(0.4993))%20)%20%5C%5C%0A%5Ctextrm%7BNLL%7D%20&amp;=%20-%20%5Clog(0.4993)%0A%5Cend%7Balign%7D"></p>
<p>From which we see that it’s just the negative log of the probability associated with the ground truth class.</p>
<p>Since this computes only the NLL per sample, we also need a way to combine the NLL across the samples in our batch. We can do this either by summing or averaging, averaging has the advantage that the size of the loss remains the same when we change the batch-size, so let’s use that:</p>
<div class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb13" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> nll(probs, labels):</span>
<span id="cb13-2">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># probs: shape [32, 3]</span></span>
<span id="cb13-3">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># labels: shape [32]</span></span>
<span id="cb13-4">    </span>
<span id="cb13-5">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># this plucks out the probability of the ground truth label per sample, </span></span>
<span id="cb13-6">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># it uses "numpy's integer array indexing":</span></span>
<span id="cb13-7">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># https://numpy.org/doc/stable/user/basics.indexing.html#integer-array-indexing</span></span>
<span id="cb13-8">    probs_ground_truth_class <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> probs[<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(labels)), labels] <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># shape: [32]</span></span>
<span id="cb13-9">    </span>
<span id="cb13-10">    nll <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>torch.log(probs_ground_truth_class).mean() <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># shape: []</span></span>
<span id="cb13-11">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> nll</span></code></pre></div>
</div>
<div class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb14" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1">nll(probs, labels)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="10">
<pre><code>tensor(1.3465)</code></pre>
</div>
</div>
<section id="using-pytorch" class="level2">
<h2 class="anchored" data-anchor-id="using-pytorch">Using PyTorch</h2>
<p>Instead of using our custom <code>softmax</code>, we can also use the build-in softmax function from PyTorch:</p>
<div class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb16" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1">p <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> F.softmax(logits, dim<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>) <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># dim=1 --&gt; compute the sum across the columns</span></span>
<span id="cb16-2">nll(p, labels)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="11">
<pre><code>tensor(1.3465)</code></pre>
</div>
</div>
<p>Instead of using our custom <code>nll</code> we can also use the build-in version from PyTorch. However, <code>nll_loss</code> expects the log of the softmax (for numerical stability) so instead of <code>softmax</code> we have to use <code>log_softmax</code>:</p>
<div class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb18" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1">p <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> F.log_softmax(logits, dim<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb18-2"></span>
<span id="cb18-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Assert that indeed the log_softmax is just the softmax followed by a log</span></span>
<span id="cb18-4"><span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">assert</span> torch.allclose(p, F.softmax(logits, dim<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>).log())</span>
<span id="cb18-5"></span>
<span id="cb18-6">torch.nn.functional.nll_loss(p, labels)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="16">
<pre><code>tensor(1.3465)</code></pre>
</div>
</div>
<p>The combination of <code>softmax</code> and <code>nll</code> is called cross entropy, so we can also use PyTorch’s build-in version of that:</p>
<div class="cell" data-execution_count="17">
<div class="sourceCode cell-code" id="cb20" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1">F.cross_entropy(logits, labels)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="17">
<pre><code>tensor(1.3465)</code></pre>
</div>
</div>
<p>Instead of the methods in <code>nn.functional</code>, we can also use classes. For that, we first create an instance of the object, and then “call” the instance:</p>
<div class="cell" data-execution_count="18">
<div class="sourceCode cell-code" id="cb22" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1">ce <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.nn.CrossEntropyLoss() <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># create a CrossEntropyLoss instance</span></span>
<span id="cb22-2">ce(logits, labels) <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># calling the instance with the arguments returns the cross entropy</span></span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="18">
<pre><code>tensor(1.3465)</code></pre>
</div>
</div>
<p>Similarly, we can use classes for the <code>log_softmax</code> and <code>nll_loss</code> functions</p>
<div class="cell" data-execution_count="19">
<div class="sourceCode cell-code" id="cb24" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1">ls <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.nn.LogSoftmax(dim<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb24-2">nll <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.nn.NLLLoss()</span>
<span id="cb24-3"></span>
<span id="cb24-4">p <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> ls(logits)</span>
<span id="cb24-5">nll(p, labels)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="19">
<pre><code>tensor(1.3465)</code></pre>
</div>
</div>
<p>This is practical, if we want specify custom behavior of the loss function ahead of time of calling the actual loss function. For example, let’s say we want to compute the cross entropy loss based on ‘sums’ instead of ‘averages’. Then when using the method in <code>F</code> we would do:</p>
<div class="cell" data-execution_count="36">
<div class="sourceCode cell-code" id="cb26" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1">F.cross_entropy(logits, labels, reduction<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'sum'</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="36">
<pre><code>tensor(43.0866)</code></pre>
</div>
</div>
<p>So whenever we call the loss, we have to specify the additional <code>reduction</code> argument.</p>
<p>Whereas when using the loss classes, we can instantiate the class with that <code>reduction</code> argument, and then call the instance as per usual without passing anything but the logits and the labels:</p>
<div class="cell" data-execution_count="37">
<div class="sourceCode cell-code" id="cb28" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># instantiate </span></span>
<span id="cb28-2">ce <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.nn.CrossEntropyLoss(reduction<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'sum'</span>)</span>
<span id="cb28-3"></span>
<span id="cb28-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># at some other point in your code, compute the loss as per default</span></span>
<span id="cb28-5">ce(logits, labels)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="37">
<pre><code>tensor(43.0866)</code></pre>
</div>
</div>
<p>This is practical when the loss function is getting called by another object to which we don’t have easy access. So that we can’t easily change the arguments for that call. This is for example the case when using the FastAI <code>Learner</code> class, to which we pass the loss function which then get’s called by the <code>Learner</code> object with the default arguments (<code>logits</code> and <code>labels</code>). By using the classes, we can specify the reduction argument ahead of time and pass that instance to the <code>Learner</code> class.</p>


</section>

 ]]></description>
  <category>Loss functions</category>
  <category>Softmax</category>
  <category>NLL</category>
  <category>Cross entropy</category>
  <category>Code</category>
  <guid>https://lucasvw.github.io/posts/05_crossentropy/index.html</guid>
  <pubDate>Wed, 15 Mar 2023 00:00:00 GMT</pubDate>
  <media:content url="https://lucasvw.github.io/posts/05_crossentropy/image.png" medium="image" type="image/png" height="82" width="144"/>
</item>
<item>
  <title>Fast matrix multiplications</title>
  <dc:creator>Lucas van Walstijn</dc:creator>
  <link>https://lucasvw.github.io/posts/04_matmul/index.html</link>
  <description><![CDATA[ 




<p>Matrix multiplications are kind of boring, so why write a blog post about them? Well, matrix multiplications are the most basic computation that is being performed by neural networks. So it’s probably good to be familiar with them (although we never do them by hand). Also, we are going to focus on speeding them up by doing vectorization. Vectorization is something we often have to do, to make sure everything runs as quickly as possible, and it’s thus a good exercise to understand how to achieve this. Especially since it involves being very familiar with matrices, their shapes, broadcasting operations and the like.</p>
<p>This post follows the first lecture of Part 2 of the FastAI course (2019), I will provide some additional explanations, and present one other optimization that is not presented in the <a href="https://%20youtu.be/4u8FxNEDUeg?t=2392">lecture</a>.</p>
<section id="definition" class="level2">
<h2 class="anchored" data-anchor-id="definition">Definition</h2>
<p>Matrix multiplication is not difficult, it basically goes like this:</p>
<ul>
<li>For matrix A of size <code>[ar x ac]</code> &nbsp; (<code>[4 x 3]</code> in the image below)</li>
<li>and matrix B of size <code>[br x bc]</code> &nbsp; (<code>[3 x 2]</code> in the image below)</li>
<li>the matrix product <code>A * B</code> is of size <code>[ar x bc]</code> (<code>[4 x 2]</code> in the image below).</li>
<li>So the matrix product is thus only defined when <code>ac == br</code> (<code>3 == 3</code> in the image below)</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://lucasvw.github.io/posts/04_matmul/image.png" class="img-fluid figure-img"></p>
</figure>
</div>
<p>So for any valid matrix multiplication, we have three dimensions that need to considered:</p>
<ul>
<li><code>ar</code>: the row dimension of matrix A. The size of this dimension will become the size of the row dimension of the output matrix (black arrow in the image above)</li>
<li><code>bc</code>: the column dimension of matrix B. The size of this dimension will become the size of the column dimension of the output matrix (purple arrow in the image above)</li>
<li><code>ac</code>: the column dimension of Matrix A and <code>br</code>: the row dimension of matrix B: <strong>they need to be equal</strong> (red arrow in the image above)</li>
</ul>
<p>Why do <code>ac</code> and <code>bc</code> need to be equal? Well, because we take the inner product over this dimension when computing the cell values of the new matrix, and inner-products are only defined for vectors of equal length. Below, I will also refer to this dimension as the dimension over which we collapse (or the “collapsible” dimension), since in the output matrix, this dimension is no longer present.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://lucasvw.github.io/posts/04_matmul/image1.png" class="img-fluid figure-img"></p>
</figure>
</div>
<p>In other words, to compute cell <img src="https://latex.codecogs.com/png.latex?C_%7Bi,j%7D"> we take the inner product between row <code>i</code> of matrix A and column <code>j</code> of matrix B. Let’s have a look at one other cell, to make sure we understand fully what’s going on. In the next figure we compute the value for cell <img src="https://latex.codecogs.com/png.latex?C_%7B3,2%7D">, we thus take the inner-product between row 3 of matrix A and column 2 of matrix B:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://lucasvw.github.io/posts/04_matmul/image2.png" class="img-fluid figure-img"></p>
</figure>
</div>
<p>Let’s do this in code and confirm what we have established above about the shapes of the matrices:</p>
<div class="cell" data-execution_count="21">
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> torch</span>
<span id="cb1-2"></span>
<span id="cb1-3">a <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.randn(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>)</span>
<span id="cb1-4">b <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.randn(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="22">
<div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Confirm the shape of the output matrix</span></span>
<span id="cb2-2">(a<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">@</span>b).shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="22">
<pre><code>torch.Size([4, 2])</code></pre>
</div>
</div>
<div class="cell" data-execution_count="153">
<div class="sourceCode cell-code" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Confirm the value of one output cell (C00)</span></span>
<span id="cb4-2">C00_manual <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (a[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> b[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> (a[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> b[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> (a[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> b[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>])</span>
<span id="cb4-3">C00_auto <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (a<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">@</span>b)[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]</span>
<span id="cb4-4"></span>
<span id="cb4-5"><span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">assert</span> torch.allclose(C00_manual, C00_auto)</span></code></pre></div>
</div>
<p>With what we know, let’s create our own <code>matmul</code> function:</p>
<div class="cell" data-execution_count="115">
<div class="sourceCode cell-code" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> matmul(a, b):</span>
<span id="cb5-2">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># fill in the sizes of the dimensions</span></span>
<span id="cb5-3">    ar, ac <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> a.shape</span>
<span id="cb5-4">    br, bc <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> b.shape</span>
<span id="cb5-5"></span>
<span id="cb5-6">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># assert that our matrices can be multiplied </span></span>
<span id="cb5-7">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">assert</span> ac <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> br</span>
<span id="cb5-8"></span>
<span id="cb5-9">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># create an output tensor of the expected size (ar x bc)</span></span>
<span id="cb5-10">    out <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.zeros(ar, bc)</span>
<span id="cb5-11"></span>
<span id="cb5-12">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># iterate over the rows of the output matrix (--&gt; length ar)</span></span>
<span id="cb5-13">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(out.shape[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]):</span>
<span id="cb5-14">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># iterate over the columns of the output matrix (--&gt; length bc)</span></span>
<span id="cb5-15">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> j <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(out.shape[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>]):</span>
<span id="cb5-16">            <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># iterate over the "collapsed" dimension (--&gt; length ac and length br), </span></span>
<span id="cb5-17">            <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> k <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(ac):</span>
<span id="cb5-18">                out[i, j] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+=</span> a[i, k] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> b[k, j]</span>
<span id="cb5-19">    </span>
<span id="cb5-20">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> out</span>
<span id="cb5-21"></span>
<span id="cb5-22"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Confirm that the result is correct</span></span>
<span id="cb5-23"><span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">assert</span> torch.allclose(matmul(a,b), a<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">@</span>b)</span></code></pre></div>
</div>
<p>Although this is functionally correct, it’s not very efficient. In fact, to compute the value of one cell of the output matrix, we are doing three separate multiplications. In other words, for each cell <code>out[i,j]</code> we are calling three times (once for every value of <code>k</code>):</p>
<pre><code>out[i, j] += a[i, k] * b[k, j]</code></pre>
<p>Let’s try to reduce the computation of one cell to just one single call.</p>
</section>
<section id="first-improvement" class="level2">
<h2 class="anchored" data-anchor-id="first-improvement">First improvement</h2>
<p>To do so, we need to get rid of the loop over the “collapsible” dimension <code>k</code>. We can simply do this by replacing the <code>k</code> with a <code>:</code>, so that we select the whole dimension instead of just one element in that dimension. The multiplication (<code>*</code>) is doing an element wise multiplication, so we have to wrap the result with a <code>.sum()</code>.</p>
<div class="cell" data-execution_count="114">
<div class="sourceCode cell-code" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> matmul2(a, b):</span>
<span id="cb7-2">    ar, ac <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> a.shape</span>
<span id="cb7-3">    br, bc <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> b.shape</span>
<span id="cb7-4">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">assert</span> ac <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> br</span>
<span id="cb7-5"></span>
<span id="cb7-6">    out <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.zeros(ar,bc)</span>
<span id="cb7-7">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># iterate over the rows of the output matrix (i)</span></span>
<span id="cb7-8">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(out.shape[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]):</span>
<span id="cb7-9">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># iterate over the columns of the output matrix (j)</span></span>
<span id="cb7-10">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> j <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(out.shape[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>]):</span>
<span id="cb7-11">            out[i, j] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (a[i, :] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> b[:, j]).<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">sum</span>()</span>
<span id="cb7-12">    </span>
<span id="cb7-13">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> out</span>
<span id="cb7-14"></span>
<span id="cb7-15"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Confirm that the result is correct</span></span>
<span id="cb7-16"><span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">assert</span> torch.allclose(matmul(a,b), a<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">@</span>b)</span></code></pre></div>
</div>
</section>
<section id="second-improvement" class="level2">
<h2 class="anchored" data-anchor-id="second-improvement">Second improvement</h2>
<p>The improvement above, gives us the value of a cell in one single call:</p>
<pre><code>out[i, j] = (a[i, :] * b[:, j]).sum()</code></pre>
<p>This is great, let’s try to vectorize this even further, and get rid of the second loop (the loop over <code>j</code>), this means that we need to compute the values of a single row of the output matrix in one call, e.g.</p>
<pre><code>out[i,:] = ...</code></pre>
<p>We know that the value of cell <img src="https://latex.codecogs.com/png.latex?C_%7Bij%7D"> is the inner product between row <code>i</code> of A and column <code>j</code> of B. We also know that any row of matrix C will have two values. Let’s compute them manually:</p>
<div class="cell" data-execution_count="99">
<div class="sourceCode cell-code" id="cb10" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1">out_00 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (a[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>,:] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> b[:,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]).<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">sum</span>()</span>
<span id="cb10-2">out_01 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (a[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>,:] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> b[:,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>]).<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">sum</span>()</span>
<span id="cb10-3"></span>
<span id="cb10-4">C0_manual <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.stack([out_00, out_01])</span>
<span id="cb10-5">C0_auto <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (a<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">@</span>b)[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]</span>
<span id="cb10-6"></span>
<span id="cb10-7"><span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">assert</span> torch.allclose(C0_manual, C0_auto)</span>
<span id="cb10-8"></span>
<span id="cb10-9"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f'</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>out_00<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">'</span>, <span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f'</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>out_01<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">'</span>, <span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f'</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>C0_manual<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">'</span>, sep<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'</span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">\n</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'</span>)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>out_00=tensor(-0.0213)
out_01=tensor(0.3668)
C0_manual=tensor([-0.0213,  0.3668])</code></pre>
</div>
</div>
<p>Observe that for the computation of one row of output, we need:</p>
<ul>
<li>one single row of A (<code>a[0,:]</code>)</li>
<li>the full matrix of B, we need both the first (<code>b[:,0]</code>) column and the second column (<code>b[:,1]</code>).</li>
</ul>
<p>Let’s check the sizes of both and see whether we can use broadcasting:</p>
<div class="cell" data-execution_count="100">
<div class="sourceCode cell-code" id="cb12" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f'</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>a[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>,:]<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span>shape<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">'</span>, <span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f'</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>b<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span>shape<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">'</span>, sep<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'</span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">\n</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'</span>)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>a[0,:].shape=torch.Size([3])
b.shape=torch.Size([3, 2])</code></pre>
</div>
</div>
<p>Unfortunately, size <code>[3]</code> and <code>[3,2]</code> don’t broadcast. To make them broadcast, we have to add an empty dimension at the end of the row of the A matrix. Then, the shapes <code>[3, 1]</code> and <code>[3, 2]</code> can be broadcasted to another by duplicating the former in the column direction:</p>
<div class="cell" data-execution_count="102">
<div class="sourceCode cell-code" id="cb14" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1">t <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> a[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>,:].unsqueeze(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>) <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># [3, 1]</span></span>
<span id="cb14-2"></span>
<span id="cb14-3">t.broadcast_to(b.shape) <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># [3, 2]</span></span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="102">
<pre><code>tensor([[ 0.9193,  0.9193],
        [-0.0426, -0.0426],
        [ 1.3566,  1.3566]])</code></pre>
</div>
</div>
<p>Now that both object are the same size we can do an element-wise multiplication and then sum over the rows to arrive at an output of size <code>[1,2]</code>:</p>
<div class="cell" data-execution_count="156">
<div class="sourceCode cell-code" id="cb16" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1">C0_manual <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (t<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>b).<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">sum</span>(dim<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>)</span>
<span id="cb16-2">C0_auto <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (a<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">@</span>b)[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>,:]</span>
<span id="cb16-3"></span>
<span id="cb16-4"><span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">assert</span> torch.allclose(C0_manual, C0_auto)</span>
<span id="cb16-5"></span>
<span id="cb16-6"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f'</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>C0_manual<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">'</span>, <span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f'</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>C0_manual<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span>shape<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">'</span>, sep<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'</span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">\n</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'</span>)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>C0_manual=tensor([-0.0213,  0.3668])
C0_manual.shape=torch.Size([2])</code></pre>
</div>
</div>
<p>So let’s implement this:</p>
<div class="cell" data-execution_count="116">
<div class="sourceCode cell-code" id="cb18" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> matmul3(a, b):</span>
<span id="cb18-2">    ar, ac <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> a.shape</span>
<span id="cb18-3">    br, bc <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> b.shape</span>
<span id="cb18-4">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">assert</span> ac <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> br</span>
<span id="cb18-5"></span>
<span id="cb18-6">    out <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.zeros(ar,bc)</span>
<span id="cb18-7">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># iterate over the rows of the output matrix (i)</span></span>
<span id="cb18-8">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(out.shape[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]):</span>
<span id="cb18-9">        out[i, :] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (a[i, :].unsqueeze(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> b).<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">sum</span>(dim<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>)</span>
<span id="cb18-10">    </span>
<span id="cb18-11">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> out</span>
<span id="cb18-12"></span>
<span id="cb18-13"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Confirm that the result is correct</span></span>
<span id="cb18-14"><span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">assert</span> torch.allclose(matmul(a,b), a<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">@</span>b)</span></code></pre></div>
</div>
</section>
<section id="third-improvement" class="level2">
<h2 class="anchored" data-anchor-id="third-improvement">Third improvement</h2>
<p>For the final improvement, we need to get rid of the only remaining loop over the rows of our output matrix (<code>i</code>). So let’s understand very well what we are having at the moment:</p>
<ul>
<li>We are iterating over the (4) rows of our output matrix</li>
<li>For each row, we are computing the (2) values of our row at once by doing <code>out[i, :] = (a[i, :].unsqueeze(-1) * b).sum(dim=0)</code> and let’s break this down once again in steps:
<ol type="1">
<li><code>a[i, :]</code> has shape <code>[3]</code> and represents one row of A</li>
<li>with <code>a[i, :].unsqueeze(-1)</code> we add an extra dimension so that we can broadcast, the result has shape <code>[3, 1]</code></li>
<li><code>b</code> has shape <code>[3, 2]</code> and is the full B matrix</li>
<li>element-wise multiplication of 2. and 3. gives a matrix of shape <code>[3, 2]</code></li>
<li>by summing over the rows (<code>.sum(dim=0)</code>) we arrive at the result of shape <code>[2]</code></li>
</ol></li>
</ul>
<p>We want to improve this by <strong>instead of iterating over the 4 rows, do these computations all at once for all rows</strong>. So let’s start by not selecting one row of A (<code>a[i,:]</code>) but instead just the whole <code>a</code> matrix:</p>
<ol type="1">
<li><code>a</code> has shape <code>[4, 3]</code></li>
<li>similarly to what we did before, we can <code>a.unsqueeze(-1)</code> to add an extra dimension, the result has shape <code>[4, 3, 1]</code></li>
<li>same as before, <code>b</code> has shape <code>[3, 2]</code> and is the full B matrix</li>
<li>broadcasting of 2. and 3. will do the following:
<ul>
<li><code>a.unsqueeze(-1)</code> has shape <code>[4, 3, 1]</code> and get’s expanded to <code>[4, 3, 2]</code> to match the shape of <code>b</code> (<code>[3, 2]</code>)</li>
<li>but <code>b</code> also needs to match <code>a</code>, first an additional empty dimension is added in the front: <code>[1, 3, 2]</code> and then it get’s expanded to <code>[4, 3, 2]</code></li>
<li>next, the element-wise multiplication of 2. and 3. gives a matrix (tensor) of shape <code>[4, 3, 2]</code>, let’s call it <code>t</code>. It’s import to realize what this <code>t</code> represents. For that, notice that the first dimension (length 4) and last dimension (length 2) are the dimensions of our output matrix (<code>[4, 2]</code>). <strong>The middle dimension (length 3) represents the element wise multiplications of any row in matrix A and any column of matrix B</strong>. So by doing for example <code>t[i, :, j].sum()</code> we get the value for cell <img src="https://latex.codecogs.com/png.latex?C_%7Bi,j%7D"> of our output matrix!</li>
</ul></li>
<li>This means, that to arrive at the final result, we will have to collapse (sum) over the middle dimension!</li>
</ol>
<div class="cell" data-execution_count="154">
<div class="sourceCode cell-code" id="cb19" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> matmul4(a, b):</span>
<span id="cb19-2">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> (a.unsqueeze(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> b).<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">sum</span>(dim<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb19-3"></span>
<span id="cb19-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Confirm that the result is correct</span></span>
<span id="cb19-5"><span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">assert</span> torch.allclose(matmul(a,b), a<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">@</span>b)</span></code></pre></div>
</div>
</section>
<section id="timings" class="level2">
<h2 class="anchored" data-anchor-id="timings">Timings</h2>
<p>To see what kind of a speed-up we have achieved, let’s look at the timings of our first version with three loops and the timings of our optimized version:</p>
<div class="cell" data-execution_count="147">
<div class="sourceCode cell-code" id="cb20" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%</span>timeit <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>n <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1000</span> matmul(a,b)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>318 µs ± 13.7 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)</code></pre>
</div>
</div>
<div class="cell" data-execution_count="155">
<div class="sourceCode cell-code" id="cb22" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%</span>timeit <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>n <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1000</span> matmul4(a,b)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>10.7 µs ± 1.46 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)</code></pre>
</div>
</div>
<p>Nice, our optimized version is about 30 times faster then our un-optimized version with 3 loops! Additionally, let’s check the timings of doing the matrix multiplication with <code>einsum</code>:</p>
<div class="cell" data-execution_count="151">
<div class="sourceCode cell-code" id="cb24" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%</span>timeit <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>n <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1000</span> torch.einsum(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'ij,jk-&gt;ik'</span>, a, b)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>25.9 µs ± 3.78 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)</code></pre>
</div>
</div>
<p>Surprisingly, our optimized version is twice as fast as <code>einsum</code>. This is certainly something I didn’t expect.</p>
<p>Finally, let’s also check the timings of using the <code>@</code> operator:</p>
<div class="cell" data-execution_count="152">
<div class="sourceCode cell-code" id="cb26" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%</span>timeit <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>n <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1000</span> a<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">@</span>b</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>3.29 µs ± 522 ns per loop (mean ± std. dev. of 7 runs, 1,000 loops each)</code></pre>
</div>
</div>
<p>As expected, this is even faster then our optimized version, probably because it runs in optimized C / CUDA code</p>


</section>

 ]]></description>
  <category>Foundations</category>
  <category>Maths</category>
  <category>Vectorization</category>
  <category>Linear Algebra</category>
  <category>Code</category>
  <guid>https://lucasvw.github.io/posts/04_matmul/index.html</guid>
  <pubDate>Tue, 07 Mar 2023 00:00:00 GMT</pubDate>
  <media:content url="https://lucasvw.github.io/posts/04_matmul/image.png" medium="image" type="image/png" height="89" width="144"/>
</item>
<item>
  <title>First competition🏅</title>
  <dc:creator>Lucas van Walstijn</dc:creator>
  <link>https://lucasvw.github.io/posts/03_aiornot/index.html</link>
  <description><![CDATA[ 




<p>In the past couple of weeks I have participated in the first ever Hugging Face competition: <a href="https://huggingface.co/spaces/competitions/aiornot" target="_blank">aiornot</a>. And as a matter of fact, it was also my first competition to participate in! The competition consisted of 62060 images (18618 train and 43442 test images) which were either created by an AI or not (binary image classification).</p>
<p>Today, the competition has finished and the private leaderboard has been made public. I’m super happy (and proud 😇) that I finished in <strong>15th place</strong> (98 participants):</p>
<p><img src="https://lucasvw.github.io/posts/03_aiornot/screenshot.png" class="img-fluid"></p>
<section id="credit-where-credit-is-due" class="level2">
<h2 class="anchored" data-anchor-id="credit-where-credit-is-due">Credit where credit is due:</h2>
<section id="hugging-face" class="level4">
<h4 class="anchored" data-anchor-id="hugging-face"><strong>🤗 Hugging Face</strong></h4>
<p>I would like to thank Hugging Face and in particular <a href="https://twitter.com/abhi1thakur" target="_blank">Abhishek Thakur</a> for organizing this competition. I started looking for a first competition at Kaggle a few weeks back, and was very interested in the <a href="https://www.kaggle.com/competitions/rsna-breast-cancer-detection" target="_blank">RSNA competition</a> but quickly found that it was probably a bit too complicated for my first competition. I then saw a tweet from Abhishek announcing this competition and found it a perfect competition to get started.</p>
</section>
<section id="fastai" class="level4">
<h4 class="anchored" data-anchor-id="fastai"><strong>fastai</strong></h4>
<p>In the past month I have been following the fastai <a href="https://course.fast.ai/" target="_blank">course</a> and I am extremely grateful to <a href="https://twitter.com/jeremyphoward" target="_blank">Jeremy Howard</a> and <a href="https://twitter.com/GuggerSylvain" target="_blank">Sylvain Gugger</a> for creating fastai. The book, the course, the videos and the great community they have built is really something special and is perfectly tailored for anybody who wants to get started with Deep Learning. Without fastai I could never have pulled this off 🙏.</p>
</section>
</section>
<section id="learnings-and-notes" class="level2">
<h2 class="anchored" data-anchor-id="learnings-and-notes">Learnings and notes</h2>
<ul>
<li><p>I quickly learned that data augmentation didn’t work well on this data. Initially I was a bit surprised by this, but upon inspection of the images I arrived at the following intuition. Normally we want to classify images by what’s being displayed in the image. So 2 images of a bike should both be classified as such. However, in this dataset we can have images of the same object but if one is created by an AI, and the other is not then they should be classified differently. So instead of looking at what’s being displayed, it probably has to learn more about the style or the way the image is built up. I can imagine that data augmentation makes this more difficult, especially warping, affine transformations and brightness, contrast augmentations. I was happily surprised to find that the <a href="https://huggingface.co/spaces/competitions/aiornot/discussions/29" target="_blank">2nd</a> and <a href="https://huggingface.co/spaces/competitions/aiornot/discussions/30" target="_blank">4th</a> place solutions also didn’t use these data augmentation!</p></li>
<li><p>Training on larger images works very well. I got a large performance boost for switching to sizes of 416. Jeremy Howard mentioned that this generally works well, and I think because of the nature of these images it worked especially well. To train large models on large images, I heavily relied on Gradient Accumulation to not have to reduce the batchsize.</p></li>
<li><p>Transformer based models such as SWIN and VIT performed not as good as models based on convolutions, I used the convnext models.</p></li>
<li><p>Progressive resizing didn’t work for me.</p></li>
<li><p>I tried training on 5 epochs and 10 epochs. 10 epochs never gave me better results.</p></li>
</ul>
<p>Last but not least:</p>
<p>Participating in competitions is very motivating and rewarding. Working individually through courses, exercises and lecture notes is very interesting, but you don’t get a lot of feedback to how you are doing. <em>Am I doing well? Should I spend more time on investigations into certain areas?</em> When participating in a real-world competition you have a very clear goal, and you get immediate feedback on how you are doing. This type of project based learning has the advantage that it’s very clear what you need to focus on: anything that you encounter during the project.</p>
<p>It’s also great that it has a finite timeline, so that afterwards you can have a sense of achievement which motivates a lot. The Germans have a very nice word for this: <em>Erfolgserlebnis</em>.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://lucasvw.github.io/posts/03_aiornot/ss2.png" class="img-fluid figure-img" width="500"></p>
<figcaption class="figure-caption">Image for <a href="https://stablediffusionweb.com/#demo">Stable Diffusion</a> prompt: <em>“Sense of achievement when finishing my first ever machine learning competition”</em></figcaption>
</figure>
</div>


</section>

 ]]></description>
  <category>Deep Learning</category>
  <category>Image Classification</category>
  <category>Competition</category>
  <guid>https://lucasvw.github.io/posts/03_aiornot/index.html</guid>
  <pubDate>Wed, 01 Mar 2023 00:00:00 GMT</pubDate>
  <media:content url="https://lucasvw.github.io/posts/03_aiornot/image.png" medium="image" type="image/png" height="71" width="144"/>
</item>
<item>
  <title>Paperspace setup</title>
  <dc:creator>Lucas van Walstijn</dc:creator>
  <link>https://lucasvw.github.io/posts/02_paperspace_setup/index.html</link>
  <description><![CDATA[ 




<p>Most people don’t have a GPU installed in their working machine that is suited for Deep Learning, and in fact you don’t need to. It’s quite easy to setup a remote GPU server nowadays, and in this blog I will explain how to do so with <a href="https://www.paperspace.com/gradient">Paperspace Gradient</a>.</p>
<p>I started using Paperspace because of a recommendation from Jeremy Howard in his <a href="https://www.youtube.com/playlist?list=PLfYUBJiXbdtSLBPJ1GMx-sQWf6iNhb8mM">Live Coding Videos</a>. If you haven’t seen these lectures, I can highly recommend them. They are a great resource on many things related to getting started with Deep Learning. Jeremy shows a lot of productivity hacks and practical tips on getting a good setup.</p>
<p>However, the Paperspace setup explanations are a bit out-dated which can lead to confusion when following along with the video’s. Also, after the recording of the videos Jeremy created some nice scripts which simplify the setup. This blog will hopefully help others to navigate this and quickly set-up a remote GPU server. I would advice anybody who wants to try Paperspace, to first watch the videos from Jeremy to have a general idea of how it works, and then follow these steps to quickly get set-up.</p>
<p>Once you have signed up to Paperspace, go to their Gradient service and create a new project. Paperspace has a free tier, as well as a pro- ($8/month) and growth-plan ($39/month). I personally signed up for the pro-plan, which has a very good value for money. You get 15Gb persistent storage and free Mid instance types. If available, I use the A4000, which is the fastest and comes with 16GB of GPU memory.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>Paperspace has both free and paid servers. The free ones come with a 6 hour usage limit, after that they are automatically shut down. The paid servers you can use as long as you like. Sometimes the free servers are out of capacity, which is a bit annoying. In my experience however most of the time I’m able to get what I need.</p>
</div>
</div>
<p>With the pro-plan you can create up to 3 servers, or “Notebooks” as they are called by Paperspace (throughout this blog I’ll refer to them as <em>Notebook Servers</em>). So let’s create one:</p>
<ul>
<li>Select the “Fast.AI” runtime</li>
<li>Select a machine, for example the Free-A4000. You can always change this when you restart your machine</li>
<li>Remove the Workspace URL under the advanced options to create a totally empty server</li>
<li>Navigate to JupyterLab</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://lucasvw.github.io/posts/02_paperspace_setup/screenshot.png" class="img-fluid figure-img" width="300"></p>
<figcaption class="figure-caption">Click the JupyterLab icon to open up a JupyterLab environment for your GPU server</figcaption>
</figure>
</div>
<section id="first-look-at-our-notebook-server" class="level2">
<h2 class="anchored" data-anchor-id="first-look-at-our-notebook-server">First look at our Notebook Server</h2>
<p>Next, let’s open a terminal and get familiar with our Server</p>
<div class="code-with-filename">
<div class="code-with-filename-file">
<pre><strong>Terminal</strong></pre>
</div>
<div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb1-1"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;</span> which <span class="ex" style="color: null;
background-color: null;
font-style: inherit;">python</span></span>
<span id="cb1-2"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">/usr/local/bin/python</span></span>
<span id="cb1-3"></span>
<span id="cb1-4"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;</span> python <span class="ex" style="color: null;
background-color: null;
font-style: inherit;">--version</span></span>
<span id="cb1-5"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">Python</span> 3.9.13</span></code></pre></div>
</div>
<p>And let’s also check the <code>PATH</code> variable:</p>
<div class="code-with-filename">
<div class="code-with-filename-file">
<pre><strong>Terminal</strong></pre>
</div>
<div class="sourceCode" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode bash code-overflow-wrap code-with-copy"><code class="sourceCode bash"><span id="cb2-1"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;</span> echo <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">$PATH</span></span>
<span id="cb2-2"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:</span> /usr/sbin:/usr/bin:/sbin:/bin:/root/mambaforge/bin</span></code></pre></div>
</div>
<p>The <code>python</code> command is thus pointing to the system Python installation. However, on the <code>PATH</code> variable we are also seeing an entry at the end mentioning mambaforge.</p>
<p>And indeed we can execute:</p>
<div class="code-with-filename">
<div class="code-with-filename-file">
<pre><strong>Terminal</strong></pre>
</div>
<div class="sourceCode" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode bash code-overflow-wrap code-with-copy"><code class="sourceCode bash"><span id="cb3-1"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;</span> mamba <span class="ex" style="color: null;
background-color: null;
font-style: inherit;">list</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">|</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">grep</span> python</span>
<span id="cb3-2"></span>
<span id="cb3-3"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">ipython</span>                   8.5.0              pyh41d4057_1    conda-forge</span>
<span id="cb3-4"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">ipython_genutils</span>          0.2.0                      py_1    conda-forge</span>
<span id="cb3-5"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">python</span>                    3.10.6          h582c2e5_0_cpython    conda-forge</span>
<span id="cb3-6"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">python-dateutil</span>           2.8.2              pyhd8ed1ab_0    conda-forge</span>
<span id="cb3-7"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">python-fastjsonschema</span>     2.16.2             pyhd8ed1ab_0    conda-forge</span>
<span id="cb3-8"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">python_abi</span>                3.10                    2_cp310    conda-forge</span></code></pre></div>
</div>
<p>So we are having both a <code>mamba</code> based Python 3.10.6 and a system installation of Python 3.9.13.</p>
<p>Let’s open a Jupyter Notebook and see which Python version is running:</p>
<div class="code-with-filename">
<div class="code-with-filename-file">
<pre><strong>Untitled.ipynb</strong></pre>
</div>
<div class="sourceCode" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode bash code-overflow-wrap code-with-copy"><code class="sourceCode bash"><span id="cb4-1"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">import</span> sys</span>
<span id="cb4-2"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">sys.version</span></span></code></pre></div>
</div>
<p>Which returns: <code>'3.9.13 (main, May 23 2022, 22:01:06) \n[GCC 9.4.0]'</code>. Jupyter is thus running the system Python installation.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>In the videos Jeremy mentions that we should never use the system Python but instead always create a Mamba installation. However, since we are working here on a virtual machine that is only used for running Python, this shouldn’t be a problem. Just be aware that we are using the system Python which is totally separate from the Mamba setup.</p>
</div>
</div>
<p>Since we are running the system Python version, we can inspect all the packages that are installed:</p>
<div class="code-with-filename">
<div class="code-with-filename-file">
<pre><strong>Terminal</strong></pre>
</div>
<div class="sourceCode" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode bash code-overflow-wrap code-with-copy"><code class="sourceCode bash"><span id="cb5-1"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;</span> pip <span class="ex" style="color: null;
background-color: null;
font-style: inherit;">list</span></span>
<span id="cb5-2"></span>
<span id="cb5-3"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">...</span></span>
<span id="cb5-4"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">fastai</span>                            2.7.10</span>
<span id="cb5-5"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">fastapi</span>                           0.92.0</span>
<span id="cb5-6"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">fastbook</span>                          0.0.28</span>
<span id="cb5-7"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">fastcore</span>                          1.5.27</span>
<span id="cb5-8"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">fastdownload</span>                      0.0.7</span>
<span id="cb5-9"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">fastjsonschema</span>                    2.15.3</span>
<span id="cb5-10"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">fastprogress</span>                      1.0.3</span>
<span id="cb5-11"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">...</span></span>
<span id="cb5-12"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">torch</span>                             1.12.0+cu116</span>
<span id="cb5-13"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">torchaudio</span>                        0.12.0+cu116</span>
<span id="cb5-14"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">torchvision</span>                       0.13.0+cu116</span>
<span id="cb5-15"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">...</span></span></code></pre></div>
</div>
</section>
<section id="persisted-storage-at-paperspace" class="level2">
<h2 class="anchored" data-anchor-id="persisted-storage-at-paperspace">Persisted Storage at Paperspace</h2>
<p>In general, things are not persisted on Paperspace. So anything we store during a session, will be gone when we restart our Notebook Server. However, Paperspace comes with two special folders that are persisted. It’s important to understand how these folder works since we obviously need to persist our work. Not only that, but we also need to persist our configuration files from services lik GitHub, Kaggle and HuggingFace and potentially any other config files for tools or services we are using.</p>
<p>The persisted folders are called <code>/storage</code> and <code>/notebooks</code>. Anything in our <code>/storage</code> is <strong>shared among all the Notebook Servers</strong> we are running, whereas anything that is stored in the <code>/notebooks</code> folder is only persisted on <strong>that specific Notebook Server</strong>.</p>
</section>
<section id="set-up" class="level2">
<h2 class="anchored" data-anchor-id="set-up">Set up</h2>
<p>In the first few videos, Jeremy shows a lot of tricks on how to install new packages and set up things like Git and GitHub. After the recording of these videos, he made a <a href="https://github.com/fastai/paperspace-setup">GitHub repo</a> which facilitates this setup greatly and makes most of the steps from the videos unnecessary. So let’s use that:</p>
<div class="code-with-filename">
<div class="code-with-filename-file">
<pre><strong>Terminal</strong></pre>
</div>
<div class="sourceCode" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode bash code-overflow-wrap code-with-copy"><code class="sourceCode bash"><span id="cb6-1"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;</span> git <span class="ex" style="color: null;
background-color: null;
font-style: inherit;">clone</span> https://github.com/fastai/paperspace-setup.git</span>
<span id="cb6-2"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;</span> cd <span class="ex" style="color: null;
background-color: null;
font-style: inherit;">paperspace-setup</span></span>
<span id="cb6-3"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;</span> ./setup.sh</span></code></pre></div>
</div>
<p>To understand what this does, let’s have a look at <code>setup.sh</code>:</p>
<div class="code-with-filename">
<div class="code-with-filename-file">
<pre><strong>setup.py</strong></pre>
</div>
<div class="sourceCode" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode bash code-overflow-wrap code-with-copy"><code class="sourceCode bash"><span id="cb7-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#!/usr/bin/env bash</span></span>
<span id="cb7-2"></span>
<span id="cb7-3"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">mkdir</span> /storage/cfg</span>
<span id="cb7-4"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">cp</span> pre-run.sh /storage/</span>
<span id="cb7-5"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">cp</span> .bash.local /storage/</span>
<span id="cb7-6"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">echo</span> install complete. please start a new instance</span></code></pre></div>
</div>
<p>First it’s creating a new directory inside of our <code>/storage</code> folder called <code>cfg</code>. As we will see, this is where we will store all our configuration files and folders.</p>
<p>Next, the script copies 2 files to our storage folder. Let’s have a closer look at those</p>
<section id="pre-run.sh" class="level4">
<h4 class="anchored" data-anchor-id="pre-run.sh"><strong>pre-run.sh</strong></h4>
<p>During startup of a Notebook Server (upon creation or restart), Paperspace automatically executes the script it finds at <code>/storage/pre-run.sh</code>. This is really neat, since we can create a script at this location to automate our setup!</p>
<p>For the full script, click <a href="https://github.com/fastai/paperspace-setup/blob/master/pre-run.sh">here</a>, and let’s have a closer look at this first snippet:</p>
<div class="code-with-filename">
<div class="code-with-filename-file">
<pre><strong>pre-run.sh (snippet)</strong></pre>
</div>
<div class="sourceCode" id="cb8" style="background: #f1f3f5;"><pre class="sourceCode numberSource bash code-overflow-wrap number-lines code-with-copy"><code class="sourceCode bash"><span id="cb8-1"><span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> p <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> .local .ssh .config .ipython .fastai .jupyter .conda .kaggle</span>
<span id="cb8-2"><span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">do</span></span>
<span id="cb8-3">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">[</span> <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">!</span> <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">-e</span> /storage/cfg/<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">$p</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">]</span><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">;</span> <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">then</span></span>
<span id="cb8-4">                <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">mkdir</span> /storage/cfg/<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">$p</span></span>
<span id="cb8-5">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">fi</span></span>
<span id="cb8-6">        <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">rm</span> <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-rf</span> ~/<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">$p</span></span>
<span id="cb8-7">        <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">ln</span> <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-s</span> /storage/cfg/<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">$p</span> ~/</span>
<span id="cb8-8"><span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">done</span></span></code></pre></div>
</div>
<p>So we are iterating through a list of folder names (<code>.local .ssh ...</code>) on line 1, and for each one we create a directory inside of <code>/storage/cfg</code> on line 4. We only do this if the directory doesn’t already exist on line 3. Next, each of these folders is symlinked to the home directory (<code>~/</code>) on line 7.</p>
<p>This means that:</p>
<ol type="1">
<li>When we store something in any of these symlinked folders (e.g.&nbsp;<code>~/.local</code>), it’s actually being written to the associated storage folder (e.g.&nbsp;<code>/storage/cfg/.local</code>) because of the symlink.</li>
<li>Whenever we restart our Notebook Server, all the stuff that has previously been persisted (e.g.&nbsp;in <code>/storage/cfg/.local</code>) are made available again in the home directory (e.g.&nbsp;<code>~/.local</code>).</li>
</ol>
<p>This is very nice, because as it turns out: many tools keep their configuration files in this home folder. So by persisting this data, they will keep working across restarts of our Notebook servers.</p>
<p>Let’s a closer look at the folders we are persisting:</p>
<section id="local" class="level5">
<h5 class="anchored" data-anchor-id="local"><strong>.local</strong></h5>
<p>We saw before that the FastAI runtime comes with a number of installed Python packages. If we want to install additional packages, we could do: <code>pip install &lt;package&gt;</code>. However, pip installs the packages in <code>/usr/local/lib</code>, and are thus not persisted. To make sure our packages are persisted, we can instead install with <code>pip install --user &lt;package&gt;</code>. This <code>--user</code> flag, tells <code>pip</code> to install the package only for the current user, and so it installs into the <code>~/.local</code> directory. So by persisting this folder, we make sure that we our custom installed python packages are persisted, awesome!</p>
</section>
<section id="ssh" class="level5">
<h5 class="anchored" data-anchor-id="ssh"><strong>.ssh</strong></h5>
<p>To authenticate with GitHub without using passwords, we use ssh keys. To create a pair of keys, we run: <code>ssh-keygen</code>. This creates the private key (<code>id_rsa</code>) and the public key (<code>id_rsa.pub</code>) to the <code>~/.ssh</code> folder. Once we upload the public key to GitHub we can authenticate with GitHub, and by persisting this folder we can authenticate upon restart!</p>
<p>By now you probably get the idea, any of these folders represent a certain configuration we want to persist:</p>
<ul>
<li><code>.conda</code>: contains conda/mamba installed packages</li>
<li><code>.kaggle</code>: contains a <code>kaggle.json</code> authentication file</li>
<li><code>.fastai</code>: contains downloaded datasets and some other configuration</li>
<li><code>.config</code>, <code>.ipython</code> and <code>.jupyter</code>: contain config files for various pieces of software such as matplotlib, ipython and jupyter.</li>
</ul>
<p>I personally also added <code>.huggingface</code> to this list, to make sure my HuggingFace credentials are also persisted. See <a href="https://github.com/fastai/paperspace-setup/pull/4">here</a> for the PR back into the main repo.</p>
<p>In the second part of the script we do exactly the same thing, but for a number of files instead of directories.</p>
<div class="code-with-filename">
<div class="code-with-filename-file">
<pre><strong>pre-run.sh (snippet)</strong></pre>
</div>
<div class="sourceCode" id="cb9" style="background: #f1f3f5;"><pre class="sourceCode bash code-overflow-wrap code-with-copy"><code class="sourceCode bash"><span id="cb9-1"><span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> p <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> .git-credentials .gitconfig .bash_history</span>
<span id="cb9-2"><span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">do</span></span>
<span id="cb9-3">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">[</span> <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">!</span> <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">-e</span> /storage/cfg/<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">$p</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">]</span><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">;</span> <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">then</span></span>
<span id="cb9-4">                <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">touch</span> /storage/cfg/<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">$p</span></span>
<span id="cb9-5">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">fi</span></span>
<span id="cb9-6">        <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">rm</span> <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-rf</span> ~/<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">$p</span></span>
<span id="cb9-7">        <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">ln</span> <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-s</span> /storage/cfg/<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">$p</span> ~/</span>
<span id="cb9-8"><span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">done</span></span></code></pre></div>
</div>
<p>Now that we understand <code>pre-run.sh</code>, let’s have a look at the second file we store in our <code>/storage</code> folder:</p>
</section>
</section>
<section id="bash.local" class="level4">
<h4 class="anchored" data-anchor-id="bash.local"><strong>.bash.local</strong></h4>
<div class="code-with-filename">
<div class="code-with-filename-file">
<pre><strong>.bash.local</strong></pre>
</div>
<div class="sourceCode" id="cb10" style="background: #f1f3f5;"><pre class="sourceCode bash code-overflow-wrap code-with-copy"><code class="sourceCode bash"><span id="cb10-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#!/usr/bin/env bash</span></span>
<span id="cb10-2"></span>
<span id="cb10-3"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">alias</span> mambai=<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'mamba install -p ~/.conda '</span></span>
<span id="cb10-4"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">alias</span> pipi=<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'pip install --user '</span></span>
<span id="cb10-5"></span>
<span id="cb10-6"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">export</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">PATH</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>~/.local/bin:~/.conda/bin/:<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">$PATH</span></span></code></pre></div>
</div>
<p>Paperspace runs this script whenever we open a terminal. As you can see it defines two aliases to easily install things persistently with either mamba (<code>mambai</code>) or pip (<code>pipi</code>).</p>
<p>Any <strong>binaries</strong> that are installed this way, are installed in <code>~/.local/bin</code> (through <code>pip</code>) and to <code>~/.conda/bin/</code> (through <code>mamba</code>). We need to add these paths to the <code>PATH</code> variable, to make sure we can call them from the command line.</p>
</section>
<section id="note-on-mamba" class="level3">
<h3 class="anchored" data-anchor-id="note-on-mamba">Note on Mamba</h3>
<p>At this point you might wonder why we have the Mamba installation at all, since we have seen that the system Python is used. In fact, our Mamba environment is totally decoupled from what we are using in our Jupyter notebook, and installing packages through <code>mamba</code> will <strong>not make them available in Jupyter</strong>. Instead, we should install Python packages through <code>pip</code>.</p>
<p>So what do we need Mamba for? I guess Jeremy has done this to be able to install binaries that he wants to use from the Terminal. For example, in the videos he talks about <code>ctags</code> which he installs through <code>mamba</code>. Since installing none-Python specific binaries through pip can be complicated, we can use Mamba instead. In other words, we can use it as a general package manager, somewhat similar to <code>apt-get</code>.</p>
</section>
<section id="final-words" class="level3">
<h3 class="anchored" data-anchor-id="final-words">Final words</h3>
<p>In my opinion Paperspace offers a great product for very fair money, especially if combined with the setup described in this blog!</p>


</section>
</section>

 ]]></description>
  <category>setup</category>
  <category>paperspace</category>
  <category>GPU</category>
  <category>how-to</category>
  <category>MLOps</category>
  <guid>https://lucasvw.github.io/posts/02_paperspace_setup/index.html</guid>
  <pubDate>Sun, 26 Feb 2023 00:00:00 GMT</pubDate>
  <media:content url="https://lucasvw.github.io/posts/02_paperspace_setup/image.png" medium="image" type="image/png" height="144" width="144"/>
</item>
<item>
  <title>Blog setup</title>
  <dc:creator>Lucas van Walstijn</dc:creator>
  <link>https://lucasvw.github.io/posts/01_blog_setup/index.html</link>
  <description><![CDATA[ 




<p>In this blog post I’ll explain how I created this blog, using Quarto and GitHub. In step 4 I’ll show how to setup GitHub Actions, this has advantages over the other ways to publish our blog:</p>
<ol type="1">
<li>Our source code is also stored safely on GitHub</li>
<li>We can easily create blog entries anywhere we want, especially also from our deep learning server without having to install quarto. We can simply push to the remote branch and GitHub Actions will build the blog for us.</li>
</ol>
<p>I’m working on a Macbook, and using VS Code for code editing. If you are on a Linux or Windows machine, be aware that things might be a bit different from what I describe here.</p>
<p>I am assuming you already have a GitHub account, that VS Code is installed and configured to run Python and Jupyter Notebooks.</p>
<section id="step-1-install-quarto" class="level2">
<h2 class="anchored" data-anchor-id="step-1-install-quarto">Step 1: install Quarto</h2>
<p>First of all you need to install Quarto, go <a href="https://quarto.org/docs/get-started/">here</a>, download and install the software. You should do this on the machine that you want to use for writing your blog, in my case my Macbook laptop.</p>
<p>Once installed you will have access to the quarto Command Line Interface (CLI). To make sure everything works as expected, open a terminal and execute:</p>
<div class="code-with-filename">
<div class="code-with-filename-file">
<pre><strong>Terminal</strong></pre>
</div>
<div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb1-1"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">quarto</span> <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--help</span></span></code></pre></div>
</div>
<p>This should render some outputs describing the different commands and options that are part of the Quarto CLI and shows that Quarto is installed successfully.</p>
</section>
<section id="step-2-create-a-github-repo" class="level2">
<h2 class="anchored" data-anchor-id="step-2-create-a-github-repo">Step 2: create a GitHub repo</h2>
<p>To host our blog we will use GitHub Pages, which is a service to host a website from a GitHub repository. Based on the name you pick for your repository you will create a so-called project-website or your unique user-website. For any general repo named <code>my-awesome-repo</code>, the website will be hosted on <code>https://&lt;github-username&gt;.github.io/my-awesome-repo</code>. This is a project-websites and you can create as many as you like.</p>
<p>To create your user-website, you have to name the repo exactly like this: <code>&lt;github-username&gt;.github.io</code>, the user-website will be hosted at <code>https://&lt;github-username&gt;.github.io</code>.</p>
<p>This is exactly what I want, so I create a new repo with the name: <code>lucasvw.github.io</code>.</p>
<p>I find it helpful to add a <code>.gitignore</code> file with a Python template, to which we can later add some more entries to facilitate storing the right files on GitHub. Also make sure that the repo is Public (and not set to Private). Additionally, I added a README file and choose the Apache2 License.</p>
<p>Next, I clone this repo to my machine by running:</p>
<div class="code-with-filename">
<div class="code-with-filename-file">
<pre><strong>Terminal</strong></pre>
</div>
<div class="sourceCode" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb2-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">git</span> clone git@github.com:lucasvw/lucasvw.github.io.git</span></code></pre></div>
</div>
</section>
<section id="step-3-add-a-quarto-project-to-the-repo" class="level2">
<h2 class="anchored" data-anchor-id="step-3-add-a-quarto-project-to-the-repo">Step 3: add a Quarto project to the repo</h2>
<p>Next, open VS Code and open the cloned repo. Then access the VS Code terminal and run:</p>
<div class="code-with-filename">
<div class="code-with-filename-file">
<pre><strong>Terminal</strong></pre>
</div>
<div class="sourceCode" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb3-1"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">quarto</span> create-project <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--type</span> website:blog</span></code></pre></div>
</div>
<p>This will add a number of files to our repo, which represent the basic structure of our blog. Most importantly:</p>
<ul>
<li><code>posts</code>: here we will create our blog entries (one subfolder per blog entry)</li>
<li><code>_quarto.yml</code>: configuration file for our blog such as the theme, name, GitHub and Twitter links</li>
<li><code>about.qmd</code>: source code for the “about” page.</li>
<li><code>index.qmd</code>: source code for the landing page.</li>
</ul>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p><code>.qmd</code> files are like markdown files, but with lots of additional functionality from Quarto. Go <a href="https://www.markdownguide.org/basic-syntax/">here</a> for more information on Markdown syntax and <a href="https://nbdev.fast.ai/tutorials/qmd_intro.html">here</a> for Quarto Markdown</p>
</div>
</div>
<p>To see what we currently have, let’s render our blog locally:</p>
<div class="code-with-filename">
<div class="code-with-filename-file">
<pre><strong>Terminal</strong></pre>
</div>
<div class="sourceCode" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb4-1"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">quarto</span> preview</span></code></pre></div>
</div>
<p>Alternatively, we can install the Quarto extension in VS Code, which will show a <code>render</code> button in the top right corner on any opened <code>qmd</code> file.</p>
<p>To publish the current contents to GitHub pages, we can run:</p>
<div class="code-with-filename">
<div class="code-with-filename-file">
<pre><strong>Terminal</strong></pre>
</div>
<div class="sourceCode" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb5-1"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">quarto</span> publish gh-pages</span></code></pre></div>
</div>
<p>When doing so, we get a message that we have to change the branch from which GitHub Pages builds the site. To do this, I go to <a href="https://github.com/lucasvw/lucasvw.github.io/settings/pages">https://github.com/lucasvw/lucasvw.github.io/settings/pages</a> and select <code>gh-pages</code> instead of the <code>main</code> branch.</p>
<p>And voila, in a few moments our blog will be running live at <a href="https://lucasvw.github.io/">https://lucasvw.github.io/</a></p>
</section>
<section id="step-4-finalize-set-up-github-actions" class="level2">
<h2 class="anchored" data-anchor-id="step-4-finalize-set-up-github-actions">Step 4: Finalize set-up: GitHub Actions</h2>
<p>When we run the <code>quarto publish gh-pages</code> command, Quarto processes our files and turns them into web readable files (HTML, JS, CSS etc). It stores these files in our <code>gh-pages</code> branch and pushes them to our remote GitHub repo. This is great, but it means that this doesn’t store our source files.</p>
<p>To do so, let’s first open our <code>.gitignore</code> file and make sure that it contains the following entries so that we don’t check in any files we don’t need.</p>
<div class="code-with-filename">
<div class="code-with-filename-file">
<pre><strong>.gitignore</strong></pre>
</div>
<div class="sourceCode" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode txt code-with-copy"><code class="sourceCode default"><span id="cb6-1"># Quarto</span>
<span id="cb6-2">/.quarto/</span>
<span id="cb6-3">_site/</span>
<span id="cb6-4"></span>
<span id="cb6-5"># Mac files</span>
<span id="cb6-6">.DS_Store</span></code></pre></div>
</div>
<p>Next, we can commit all the remaining files to Git and push them to our remote repo. If we ever lose access to our local machine, we can restore everything we need from GitHub.</p>
<p>However, now we have 2 things we need to do whenever we finish our work:</p>
<ul>
<li>store our source files on the main branch and push to GitHub</li>
<li>run the publish command to update the blog</li>
</ul>
<p>This is a bit annoying and it would be much better if we can just push to the main branch and GitHub would take care of building our website and updating it. This also allows us to create blog entries on any machine that has access to git, we don’t need to have quarto installed. This is particularly practical if we want to write blog entries from our deep learning server. So let’s use GitHub actions for this.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>Before you continue make sure you have at least once run a <code>quarto publish gh-pages</code> command, this is necessary for the things below to work</p>
</div>
</div>
<p>First we need to add the following snippet to <code>_quarto.yml</code></p>
<div class="code-with-filename">
<div class="code-with-filename-file">
<pre><strong>_quarto.yml</strong></pre>
</div>
<div class="sourceCode" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode yml code-with-copy"><code class="sourceCode yaml"><span id="cb7-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">execute</span><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">:</span></span>
<span id="cb7-2"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">  </span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">freeze</span><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">:</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;"> auto</span></span></code></pre></div>
</div>
<p>This will make sure that GitHub actions doesn’t execute any executable code, but will show the pre-rendered outputs it finds in the <code>_freeze</code> folder.</p>
<p>Finally, create the file <code>.github/workflows/publish.yml</code> and populate it with the following code:</p>
<div class="code-with-filename">
<div class="code-with-filename-file">
<pre><strong>.github/workflows/publish.yml</strong></pre>
</div>
<div class="sourceCode" id="cb8" style="background: #f1f3f5;"><pre class="sourceCode yml code-with-copy"><code class="sourceCode yaml"><span id="cb8-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">on</span><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">:</span></span>
<span id="cb8-2"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">  </span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">workflow_dispatch</span><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">:</span></span>
<span id="cb8-3"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">  </span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">push</span><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">:</span></span>
<span id="cb8-4"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">    </span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">branches</span><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">:</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;"> main</span></span>
<span id="cb8-5"></span>
<span id="cb8-6"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">name</span><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">:</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;"> Quarto Publish</span></span>
<span id="cb8-7"></span>
<span id="cb8-8"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">jobs</span><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">:</span></span>
<span id="cb8-9"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">  </span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">build-deploy</span><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">:</span></span>
<span id="cb8-10"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">    </span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">runs-on</span><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">:</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;"> ubuntu-latest</span></span>
<span id="cb8-11"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">    </span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">permissions</span><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">:</span></span>
<span id="cb8-12"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">      </span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">contents</span><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">:</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;"> write</span></span>
<span id="cb8-13"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">    </span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">steps</span><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">:</span></span>
<span id="cb8-14"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">      </span><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">-</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;"> </span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">name</span><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">:</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;"> Check out repository</span></span>
<span id="cb8-15"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">        </span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">uses</span><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">:</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;"> actions/checkout@v3</span></span>
<span id="cb8-16"></span>
<span id="cb8-17"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">      </span><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">-</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;"> </span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">name</span><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">:</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;"> Set up Quarto</span></span>
<span id="cb8-18"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">        </span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">uses</span><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">:</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;"> quarto-dev/quarto-actions/setup@v2</span></span>
<span id="cb8-19"></span>
<span id="cb8-20"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">      </span><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">-</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;"> </span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">name</span><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">:</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;"> Render and Publish</span></span>
<span id="cb8-21"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">        </span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">uses</span><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">:</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;"> quarto-dev/quarto-actions/publish@v2</span></span>
<span id="cb8-22"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">        </span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">with</span><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">:</span></span>
<span id="cb8-23"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">          </span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">target</span><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">:</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;"> gh-pages</span></span>
<span id="cb8-24"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">        </span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">env</span><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">:</span></span>
<span id="cb8-25"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">          </span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">GITHUB_TOKEN</span><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">:</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;"> ${{ secrets.GITHUB_TOKEN }}</span></span></code></pre></div>
</div>
<p>Once we push these things to GitHub, we are good to go. Whenever we push anything to the <code>main</code> branch, this workflow will execute and take care of updating the <code>gh-pages</code> branch and updating the blog.</p>


</section>

 ]]></description>
  <category>blogging</category>
  <category>setup</category>
  <category>how-to</category>
  <guid>https://lucasvw.github.io/posts/01_blog_setup/index.html</guid>
  <pubDate>Fri, 24 Feb 2023 00:00:00 GMT</pubDate>
  <media:content url="https://lucasvw.github.io/posts/01_blog_setup/profile.png" medium="image" type="image/png" height="133" width="144"/>
</item>
</channel>
</rss>
