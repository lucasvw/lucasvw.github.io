{
 "cells": [
  {
   "cell_type": "raw",
   "id": "5a706372-b4f8-4d32-9470-24b837947fa5",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"`nntrain` (0/n): Preliminaries\"\n",
    "author: \"Lucas van Walstijn\"\n",
    "date: \"2023-08-09\"\n",
    "categories: [foundations, PyTorch, nn.Module]\n",
    "image: \"image.png\"\n",
    "comments:\n",
    "  utterances:\n",
    "    repo: lucasvw/BlogComments\n",
    "format:\n",
    "  html:\n",
    "    code-overflow: scroll\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "438a6911-402a-4234-9a58-7e1530bcb1bb",
   "metadata": {},
   "source": [
    "In this series, I want to discuss the creation of a small PyTorch based library for training neural networks: `nntrain`. It's based off the excellent [part 2](https://course.fast.ai/) of Practical Deep Learning for Coders by Jeremy Howard, in which from lessons 13 to 18 (roughly) the development of the `miniai` library is discussed.\n",
    "\n",
    "We'll try to build everything as much as possible from scratch to understand how things work. Once the main functionality of components is implemented and verified, we can switch over to PyTorch's version. This is similar to how things are done in the course. However, this is not just a \"copy / paste\" of the course: on many occasions I take a different route, and most of the code is my own. That is not to say that all of this is meant to be extremely innovative, instead I had the following goals:\n",
    "\n",
    "- Deeply understand the training of neural networks with a focus on PyTorch\n",
    "- Try to create an even better narrative then what's presented in FastAI üôâü§∑‚Äç‚ôÇÔ∏èüôà\n",
    "- Get hands-on experience with creating a library with [`nb_dev`](https://nbdev.fast.ai/)\n",
    "\n",
    "`nb_dev` is another great project from the fastai community, which allows python libraries to be written in jupyter notebooks. This may sound a bit weird and controversial, but it has the advantage that we can create the source code for our library in the very same environment in which we want to experiment and interact with our methods, objects and structure **while we are building the library**. For more details on why this is a good idea and other nice features of `nb_dev`, see [here](https://www.fast.ai/posts/2022-07-28-nbdev2.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc98b7c4-9002-407d-90f6-ea9d8c07b8ae",
   "metadata": {},
   "source": [
    "So without further ado, let's start with some data!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "349f4381",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a4b6e1-9737-470a-980b-1aa3df5f5268",
   "metadata": {},
   "source": [
    " To keep things simple, let's use the fashion-mnist dataset. We can get the data from the huggingface datasets library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4de5add-ae69-46ee-aa4f-a38487830fa9",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5560f33795d4f909a836d1f45406647",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/2.00k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c83cbfb7d8c94ec0aea4b283cfe45bbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading metadata:   0%|          | 0.00/1.36k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fashion-MNIST is a dataset of Zalando's article images‚Äîconsisting of a training set of\n",
      "60,000 examples and a test set of 10,000 examples. Each example is a 28x28 grayscale image,\n",
      "associated with a label from 10 classes. We intend Fashion-MNIST to serve as a direct drop-in\n",
      "replacement for the original MNIST dataset for benchmarking machine learning algorithms.\n",
      "It shares the same image size and structure of training and testing splits.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset,load_dataset_builder\n",
    "\n",
    "name = \"fashion_mnist\"\n",
    "ds_builder = load_dataset_builder(name)\n",
    "print(ds_builder.info.description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a70f9b3-fef1-4a54-bf22-581c9f651a7e",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset fashion_mnist/fashion_mnist (download: 29.45 MiB, generated: 34.84 MiB, post-processed: Unknown size, total: 64.29 MiB) to /root/.cache/huggingface/datasets/fashion_mnist/fashion_mnist/1.0.0/8d6c32399aa01613d96e2cbc9b13638f359ef62bb33612b077b4c247f6ef99c1...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96135b6e859f40feb917a91d2d632d3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ceb12d93da8d47338206756873c30a38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/26.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f3f6ddcc7f44c8dbe1b3b24222a1a7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/29.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a23bbe688274c5ba8260579c9899aea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/4.42M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf2b57bcc16b402aa7d0ba9132af4aa4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/5.15k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ac53f4aa94c4a988d373db11c1d127f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/60000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset fashion_mnist downloaded and prepared to /root/.cache/huggingface/datasets/fashion_mnist/fashion_mnist/1.0.0/8d6c32399aa01613d96e2cbc9b13638f359ef62bb33612b077b4c247f6ef99c1. Subsequent calls will reuse this data.\n"
     ]
    }
   ],
   "source": [
    "ds = load_dataset(name, split='train')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba93a563-aac7-4015-9a95-c42d8d3d3749",
   "metadata": {},
   "source": [
    "`ds` is a `Dataset` object. These kind of objects appear in many Deep Learning libraries and have two main functionalities: you can index into them and they have a length:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3960543f-0fdb-4316-aef8-a3d51a42e287",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image': <PIL.PngImagePlugin.PngImageFile image mode=L size=28x28>,\n",
       " 'label': 9}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71add5de-4c4f-45bb-a694-606dd45603b2",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ea37f9-7d1e-45e0-9840-dd79d47f828d",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['image', 'label'],\n",
       "    num_rows: 60000\n",
       "})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ade5bd0-9411-4f7c-9f18-634f84931e72",
   "metadata": {},
   "source": [
    "Hugginface datasets (as opposed to PyTorch datasets) also have some properties, in this case `num_rows`, which is the length of the dataset (60000) and `features`, a dictionary giving metadata on what is returned when we index into the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4059340-2d94-4fba-be7a-2dae8760bc04",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image': Image(decode=True, id=None),\n",
       " 'label': ClassLabel(num_classes=10, names=['T - shirt / top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot'], id=None)}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5524187-43f6-484b-ac44-ae581ba3dec7",
   "metadata": {},
   "source": [
    "Let's visualize one single item:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b83ab5-7852-4b6d-91c6-30e7403dead2",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "image = ds[0]['image']\n",
    "label = ds[0]['label']\n",
    "\n",
    "figure, axs = plt.subplots()\n",
    "\n",
    "axs.imshow(ds[0]['image'], cmap='Greys')\n",
    "axs.set_title(f'Image of the first item in the dataset: label={label} -> \"{ds.features[\"label\"].int2str(label)}\"');\n",
    "axs.axis('off');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f5f664a-7e41-41a5-bf47-6e97189034a1",
   "metadata": {},
   "source": [
    "Since we want to start simple, and only later get to Datsets and Dataloaders: let's pull out the data into a tensor so we can build simple linear layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced0c08f-7529-409f-9595-3ab96a701a35",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 60000, 784)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torchvision.transforms.functional as TF   # to transform from PIL to tensor\n",
    "import torch\n",
    "\n",
    "x_train = [TF.to_tensor(i).view(-1) for i in ds['image']]\n",
    "y_train = [torch.tensor(i) for i in ds['label']]\n",
    "\n",
    "len(x_train), len(y_train), len(x_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf3867f",
   "metadata": {},
   "source": [
    "So `x_train` and `y_train` are both lists of length 60000, and an element in `x_train` has length 784 (28x28 pixels)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adde1eab",
   "metadata": {},
   "source": [
    "## Linear layers\n",
    "\n",
    "Now that we have the data, let's create our very first network operation: a linear layer which takes the 784 long flattened out image vector, and maps it to an output vector of length 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ccde6f-7b74-479b-b841-f8864033ab3f",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def lin(x, a, b):\n",
    "    return x@a + b\n",
    "\n",
    "a = torch.randn(784, 10)\n",
    "b = torch.randn(10)\n",
    "\n",
    "out = lin(x_train[0], a, b)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae6f7f3",
   "metadata": {},
   "source": [
    ":::{.callout-note}\n",
    "For details on matrix multiplications, check out this [post](https://lucasvw.github.io/posts/04_matmul/) I wrote earlier. \n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18210f04-74f8-4e1d-9f0e-7d93c4e1e4fc",
   "metadata": {},
   "source": [
    "Let's do the same for all our training data at once:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf8ca7b-50e3-435d-bb92-894eeb46a573",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 10])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = torch.stack(x_train)\n",
    "out = lin(x_train, a,b)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9796dee-5fd2-4765-9fb9-e8ae0e66d7fd",
   "metadata": {},
   "source": [
    "Nice, that's basically a forward pass through our model on all our training data! \n",
    "\n",
    "Now if we want to increase the depth of our network by adding an additional layer, we need to add a non-linearity in the middle. Why? See for example the first paragraphs of this [answer](https://stats.stackexchange.com/a/335972). \n",
    "\n",
    "Let's add a ReLu nonlinearity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41af6235-55e6-4cc6-af39-e9457945a955",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    return x.clamp_min(0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52437d1e-4d94-4181-9512-db8a2ea75aeb",
   "metadata": {},
   "source": [
    "And let's combine these into our first \"model\", consisting of two linear layers and a relu nonlinearity in the middle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36844072-8ec7-4c06-9b1f-cc966d45027c",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "n_in = 784 # number of input units (28x28)\n",
    "n_h = 50   # number of hidden units\n",
    "n_out = 10 # number of output units\n",
    "\n",
    "w1 = torch.randn(n_in, n_h)\n",
    "b1 = torch.zeros(n_h)\n",
    "w2 = torch.randn(n_h, n_out)\n",
    "b2 = torch.zeros(n_out)\n",
    "\n",
    "def model(x):\n",
    "    a1 = lin(x, w1, b1)\n",
    "    z1 = relu(a1)\n",
    "    return lin(z1, w2, b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374c9742-defa-4544-a183-3d362616f1b9",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "out = model(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae45976-f263-411b-baf9-13ad07d9f113",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 10])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615e4efe-fc6d-4ab9-b208-c2f6947e6a6d",
   "metadata": {},
   "source": [
    "Our \"model\" currently only does a forward pass through the network. And as a matter of fact, it's doing a forward pass with random weights. When training a neural network, we want to change these parameters in a way that the outputs of the network align with the outputs (`y_train`). I will not go into the details of this, but here is a great [video](https://youtu.be/VMj-3S1tku0) by Andrej Karpathy which in my opinion gives one of the best explanations into how this works.\n",
    "\n",
    "Before doing a backward pass, we first have to calculate the loss. Since the outputs represent any of the 10 classes the image corresponds with,  cross entropy is a straight forward loss function. Some details about cross entropy loss can be found in a [post](https://lucasvw.github.io/posts/05_crossentropy/) I wrote earlier. However, since we want to add the backpropagation ourselves and I don't know how to backpropagate through cross entropy (and I don't feel like spending a lot of time on it), let's use a much easier loss function for now: mean squared error (MSE). This obviously doesn't make any sense in the context of our data, but mathematically it's possible. We just have to end up with a single activation of our model instead of 10:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4499b9-baeb-4fd9-b99e-c97155ec0e4a",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "n_out = 1  # number of output units changed to 1\n",
    "\n",
    "w2 = torch.randn(n_h, n_out)\n",
    "b2 = torch.zeros(n_out)\n",
    "\n",
    "def model(x):\n",
    "    a1 = lin(x, w1, b1)\n",
    "    z1 = relu(a1)\n",
    "    return lin(z1, w2, b2)\n",
    "\n",
    "out = model(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58bb243-b528-4595-91c9-f1a6404112e6",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 1])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b55a9d-2006-46ae-8df6-2c939940d13d",
   "metadata": {},
   "source": [
    "From which we see that the outputs have an empty trailing dimension. `y_train` doesn't have this, so we have to squeeze out this empty dimension when computing the MSE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7542ce-91e4-44a5-95bd-934252611d86",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3015.2351)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mse(pred, targ): \n",
    "    return (pred.squeeze(-1)-targ).pow(2).mean() \n",
    "\n",
    "y_train = torch.stack(y_train)\n",
    "mse(out, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70062151-3121-4c1a-80b9-b88e071290ed",
   "metadata": {},
   "source": [
    "The next step will be to add the backward pass. But let's refactor our code to put things into classes, that way the backward pass can be added more easily:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256b9f6a-59c4-47f2-af46-dbabb2716f34",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "class Linear():\n",
    "    def __init__(self, n_in, n_out):\n",
    "        self.w = torch.randn(n_in, n_out)\n",
    "        self.b = torch.zeros(n_out)\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        self.inp = x                      # storing this for the backward pass\n",
    "        self.out = x@self.w + self.b      # storing this for the backward pass\n",
    "        return self.out\n",
    "    \n",
    "class Relu():\n",
    "    def __call__(self, x):\n",
    "        self.inp = x                      # storing this for the backward pass\n",
    "        self.out = x.clamp_min(0.)        # storing this for the backward pass\n",
    "        return self.out\n",
    "    \n",
    "class MSE():\n",
    "    def __call__(self, pred, targ):\n",
    "        self.pred = pred                   # storing this for the backward pass\n",
    "        self.targ = targ                   # storing this for the backward pass\n",
    "        self.out = (pred.squeeze(-1)-targ).pow(2).mean()\n",
    "        return self.out\n",
    "    \n",
    "class Model():\n",
    "    def __init__(self, n_in, n_h, n_out):\n",
    "        self.layers = [Linear(n_in, n_h), Relu(), Linear(n_h, n_out)]\n",
    "        self.loss = MSE()\n",
    "        \n",
    "    def __call__(self, x, y):\n",
    "        for l in self.layers: x = l(x)\n",
    "        return self.loss(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96646d9f-cee9-44a5-81e5-4c37c3dd94f6",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 784])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6221762e-001e-4251-a10f-935aeb60959b",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "m = Model(n_in, n_h, n_out)\n",
    "l = m(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a441f0-fa7a-419c-ae27-4cc8e79780b4",
   "metadata": {},
   "source": [
    "To add in the functionality for the backward pass, redefining the whole class is a nuisance. So instead we'll `patch` the classes. We can do this very easily by using the `fastcore` library. Let's see a small example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60baf247-adb4-4af5-81d9-107c6fbdf2be",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello üòé\n",
      "howdy ü§†\n"
     ]
    }
   ],
   "source": [
    "import fastcore.all as fc\n",
    "\n",
    "class A():\n",
    "    def hi(self): print('hello üòé')\n",
    "    \n",
    "a = A()\n",
    "a.hi()\n",
    "\n",
    "@fc.patch\n",
    "def hi(self:A): print('howdy ü§†')\n",
    "\n",
    "a.hi()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f3eb88",
   "metadata": {},
   "source": [
    "So with `fc.patch` we can extend or change the behavior of Classes that have been defined elsewhere, even on instances of the objects that are already created. Nice!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d160fba4-2957-4aef-a351-1b55a13bdfb1",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "@fc.patch\n",
    "def backward(self: Linear):\n",
    "    self.inp.g = self.out.g @ self.w.t()\n",
    "    self.w.g = self.inp.t() @ self.out.g\n",
    "    self.b.g = self.out.g.sum(0)\n",
    "    \n",
    "@fc.patch\n",
    "def backward(self: Relu):\n",
    "    self.inp.g = (self.inp>0).float() * self.out.g\n",
    "    \n",
    "@fc.patch\n",
    "def backward(self: MSE):\n",
    "    self.pred.g = 2. * (self.pred.squeeze() - self.targ).unsqueeze(-1) / self.targ.shape[0]\n",
    "    \n",
    "@fc.patch\n",
    "def backward(self: Model):\n",
    "    self.loss.backward()\n",
    "    for l in reversed(self.layers): l.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95417fa-a50e-401e-b3b3-ffc20c48fb57",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "m = Model(n_in, n_h, n_out)\n",
    "l = m(x_train, y_train)\n",
    "m.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "863ee419-38b3-45e3-815f-b7d2f6aea0fd",
   "metadata": {},
   "source": [
    "Now the actual operations in the backward methods you will just have to take for granted as I am not going to derive them. If you want, you can have some fun (?) to try and derive it yourself. What I think is most important about these formulas:\n",
    "\n",
    "1. Notice that each layer has a reference to it's inputs and it's outputs\n",
    "2. During the backward pass, each layer uses the gradient from the *outputs* and uses it to set the gradient on the *inputs*\n",
    "3. The inputs from layer $n$ are the outputs from layer $n-1$, so when the gradients are being set on the inputs from layer $n$, this means that layer $n-1$ it's outputs are being set at the same time\n",
    "4. This is the fundamental point about backpropagation of the gradient: in reverse order, layer by layer the gradients are being *propagated back* through the network using the chain rule\n",
    "5. Although we don't derive the operations, we can see that that there *exist* operations that do this. These operations are not magical, they are just the result of calculus: not very different from the fact that if $f(x) = x^2$ then $f'(x) = 2x$ and if $h(x) = f(g(x))$ then $h'(x) = f'(g(x)) * g'(x)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93c9c85-467d-4cbc-a137-f631b3b82b08",
   "metadata": {},
   "source": [
    "## First refactor: `Module` baseclass and training loop\n",
    "\n",
    "Now let's see how we can make this a little better. One thing that seems a bit silly is that in each of the `Linear`, `MSE` and `Relu` classes, we are storing explicitly the inputs and outputs when doing a forward call. As mentioned, we need this to backpropagate the gradients. However, we rather not store that explicitly all the time when creating a new layer. \n",
    "\n",
    "So let's create a base class that takes care of this:\n",
    "\n",
    "- Pack the forward functionality of each layer in a dedicated `forward` method\n",
    "- let the storing of inputs and ouputs be done in the `__call__` method of the baseclass, and call the `self.forward` method in between.\n",
    "\n",
    "This works, but there is one caveat: most layers just have one input when they are called (`x`), but the loss has 2 (`pred` and `targ`). To make this storing of the inputs generic we can store them as an array on the base class, and also pass them as positional arguments to `_backward`. This way, `forward` and `_backward` have the same arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b50394e-2d69-4c4e-9393-d1d5a41bfda8",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "class Module():\n",
    "    def __call__(self, *args):\n",
    "        self.args = args\n",
    "        self.out = self.forward(*args)\n",
    "        return self.out\n",
    "    \n",
    "    def backward(self): self._backward(*self.args)\n",
    "\n",
    "    \n",
    "class Linear(Module):\n",
    "    def __init__(self, n_in, n_out):\n",
    "        self.w = torch.randn(n_in, n_out)\n",
    "        self.b = torch.zeros(n_out)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return x@self.w + self.b\n",
    "    \n",
    "    def _backward(self, inp):\n",
    "        inp.g = self.out.g @ self.w.t()\n",
    "        self.w.g = inp.t() @ self.out.g\n",
    "        self.b.g = self.out.g.sum(0)\n",
    "    \n",
    "    \n",
    "class Relu(Module):\n",
    "    def forward(self, x):\n",
    "        return x.clamp_min(0.)\n",
    "    \n",
    "    def _backward(self, inp):\n",
    "        inp.g = (inp>0).float() * self.out.g\n",
    "\n",
    "    \n",
    "class MSE(Module):\n",
    "    def forward(self, pred, targ):\n",
    "        return (pred.squeeze(-1)-targ).pow(2).mean()\n",
    "    \n",
    "    def _backward(self, pred, targ):\n",
    "        pred.g = 2. * (pred.squeeze() - targ).unsqueeze(-1) / targ.shape[0]\n",
    "    \n",
    "    \n",
    "class Model(Module):\n",
    "    def __init__(self, n_in, n_h, n_out):\n",
    "        self.layers = [Linear(n_in, n_h), Relu(), Linear(n_h, n_out)]\n",
    "        self.loss = MSE()\n",
    "        \n",
    "    def forward(self, x, y):\n",
    "        for l in self.layers: x = l(x)\n",
    "        return self.loss(x, y)\n",
    "    \n",
    "    def backward(self):\n",
    "        self.loss.backward()\n",
    "        for l in reversed(self.layers): l.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9429f9ce-9e65-4092-a55d-2c55c2fbd36f",
   "metadata": {},
   "source": [
    "With these objects, let's create our first training loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8b1027-bdbd-4f00-90a7-346b85fbf040",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=0 | loss=14242.1\n",
      "epoch=1 | loss=1329.6\n",
      "epoch=2 | loss=135.2\n",
      "epoch=3 | loss=21.2\n",
      "epoch=4 | loss=9.7\n"
     ]
    }
   ],
   "source": [
    "epochs = 5                              # train for nr of epochs\n",
    "bs     = 1024                           # batch-size\n",
    "lr     = 0.01                           # learning rate\n",
    "m = Model(n_in, n_h, n_out)             # instantiate our model\n",
    "\n",
    "for epoch in range(epochs):             # iterate through epochs\n",
    "    for i in range(0,len(x_train), bs): # iterate through the batches\n",
    "        xb = x_train[i:i+bs]            # get minibatch \n",
    "        yb = y_train[i:i+bs]\n",
    "        \n",
    "        loss = m(xb, yb)                # forward pass\n",
    "        m.backward()                    # backward pass\n",
    "        \n",
    "        for l in m.layers:              # iterate through the layers\n",
    "            if isinstance(l, Linear):   # only update the linear layers\n",
    "                l.w += - lr * l.w.g     # update the weights\n",
    "                l.b += - lr * l.b.g     # update the bias\n",
    "\n",
    "                l.w.g = None            # reset the gradients\n",
    "                l.b.g = None\n",
    "    print(f'{epoch=} | {loss=:.1f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127d8944-5d93-423b-a0ea-55245b59b2be",
   "metadata": {},
   "source": [
    "Awesome, the loss is decreasing i.e. the model is training!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8fac5f4-d7ab-4def-bcc5-a57e2364d742",
   "metadata": {},
   "source": [
    "## Second refactor: simplify the weight update\n",
    "\n",
    "Let's try to simplify our training loop, and make it more generic. By adding functionality to our Module class so that it has a reference to it's trainable parameters, we can update the weights as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b672f76d-d436-4555-a660-0a9f8e31a2c4",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def fit(epochs):\n",
    "    for epoch in range(epochs):\n",
    "        for i in range(0,len(x_train), bs):\n",
    "            xb = x_train[i:i+bs]\n",
    "            yb = y_train[i:i+bs]\n",
    "\n",
    "            loss = m(xb, yb)\n",
    "            m.backward()\n",
    "\n",
    "            for p in m.parameters():    # model has a reference to the trainable parameters\n",
    "                p -= lr * p.g           \n",
    "            m.zero_grad()               # model can reset the gradients\n",
    "        print(f'{epoch=} | {loss=:.1f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2f0869-b537-4078-926f-279419154457",
   "metadata": {},
   "source": [
    "To do so, we will create a new baseclass (`NNModule`), from which our model and all the layers will inherit. We have the following conditions and properties:\n",
    "\n",
    "1. The class will hold a dictionary `_named_args`, in which all the named arguments are stored that are set on the Module.\n",
    "2. This is done by defining a `__setattr__` method, which stores any named argument that doesn't start with an `_` in this dictionary\n",
    "3. For the `Linear`, these named arguments will be the parameters `w` and `b`\n",
    "4. For the `Model`, these named arguments will be `layers` (an array containing the layer objects) and `loss` containing the `MSE` object.\n",
    "5. Because we want to get the parameters directly out of a layer, as well as out of the model, we need to implement some logic in `_parameters()` to iterate through the lowest \"level\" and get the actual parameters out\n",
    "6. Last but not least we have to implement a `zero_grad()` method to zero the gradients on the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa79b94-434b-4833-a673-01c8fa6065e0",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "class NNModule:\n",
    "    def __init__(self):\n",
    "        self._named_args = {}                           # [1]\n",
    "        \n",
    "    def __setattr__(self, name, value):                 # [2]\n",
    "        if not name.startswith(\"_\"): self._named_args[name] = value\n",
    "        super().__setattr__(name, value)\n",
    "        \n",
    "    def _parameters(self, obj):                         # [5]\n",
    "        for i in obj:\n",
    "            if isinstance(i, torch.Tensor): yield i\n",
    "            if isinstance(i, NNModule):\n",
    "                yield from iter(self._parameters(i._named_args.values()))\n",
    "            if isinstance(i, list):\n",
    "                yield from iter(self._parameters(i))\n",
    "        \n",
    "    def parameters(self):\n",
    "        return list(self._parameters(self._named_args.values()))\n",
    "    \n",
    "    def zero_grad(self):\n",
    "        for p in self.parameters():\n",
    "            p.g = None                                   # [6]\n",
    "        \n",
    "    def __call__(self, *args):\n",
    "        self._args = args                                # NOT stored under _named_args as \\\n",
    "        self._out = self.forward(*args)                  # it starts with \"_\"\n",
    "        return self._out\n",
    "    \n",
    "    def backward(self): self._backward(*self._args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94dc3d40-e209-47e2-89a8-77cc2b7d2ba4",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "class Linear(NNModule):\n",
    "    def __init__(self, n_in, n_out):\n",
    "        super().__init__()\n",
    "        self.w = torch.randn(n_in, n_out)               # [3] stored under _named_args \n",
    "        self.b = torch.zeros(n_out)                     # [3] stored under _named_args\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return x@self.w + self.b\n",
    "    \n",
    "    def _backward(self, inp):\n",
    "        inp.g = self._out.g @ self.w.t()\n",
    "        self.w.g = inp.t() @ self._out.g\n",
    "        self.b.g = self._out.g.sum(0)\n",
    "        \n",
    "        \n",
    "class Relu(NNModule):\n",
    "    def forward(self, x):\n",
    "        return x.clamp_min(0.)\n",
    "    \n",
    "    def _backward(self, inp):\n",
    "        inp.g = (inp>0).float() * self._out.g\n",
    "\n",
    "    \n",
    "class MSE(NNModule):\n",
    "    def forward(self, pred, targ):\n",
    "        return (pred.squeeze(-1)-targ).pow(2).mean()\n",
    "    \n",
    "    def _backward(self, pred, targ):\n",
    "        pred.g = 2. * (pred.squeeze() - targ).unsqueeze(-1) / targ.shape[0]\n",
    "        \n",
    "        \n",
    "class Model(NNModule):\n",
    "    def __init__(self, n_in, n_h, n_out):\n",
    "        super().__init__()\n",
    "        self.layers = [Linear(n_in, n_h), Relu(), Linear(n_h, n_out)]\n",
    "        self.loss = MSE()                              # [4] < and ^ are stored under _named_args\n",
    "        \n",
    "    def forward(self, x, y):\n",
    "        for l in self.layers: x = l(x)\n",
    "        return self.loss(x, y)\n",
    "    \n",
    "    def backward(self):\n",
    "        self.loss.backward()\n",
    "        for l in reversed(self.layers): l.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbefe737-7c6e-4bd5-8acc-90d1e55acc0b",
   "metadata": {},
   "source": [
    "And now we can indeed call `parameters` on both the model as well as on individual layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7be5f8-d881-44ed-966d-b34bdfd75198",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.Size([784, 50]), torch.Size([50]), torch.Size([50, 1]), torch.Size([1])]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = Model(n_in, n_h, n_out)\n",
    "[p.shape for p in m.parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd7411e-0428-446d-adec-a8be04afec81",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.Size([784, 50]), torch.Size([50])]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[p.shape for p in Linear(n_in, n_h).parameters()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c74b666-9f47-4d3d-8b02-5629790db8f3",
   "metadata": {},
   "source": [
    "Let's fit with our new training loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747d3927-1535-4a6b-abcb-5debb6d787e8",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=0 | loss=2118316928.0\n",
      "epoch=1 | loss=195283376.0\n",
      "epoch=2 | loss=18002500.0\n",
      "epoch=3 | loss=1659511.5\n",
      "epoch=4 | loss=152958.9\n"
     ]
    }
   ],
   "source": [
    "fit(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "277c05db-ec35-4c14-8b64-65f916ece110",
   "metadata": {},
   "source": [
    "## Third refactor: use `nn.Module`\n",
    "\n",
    "Finally we are in a position to use PyTorch's `nn.Module`, since we understand all of it's behavior! We can simplify:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ad3822-d3a0-4029-92d9-7e0654d9b21b",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, n_in, n_h, n_out):\n",
    "        super().__init__()\n",
    "        self.layers = [nn.Linear(n_in, n_h), nn.ReLU(), nn.Linear(n_h, n_out)]\n",
    "        for i,l in enumerate(self.layers):               # ^ we use the nn.Linear and nn.ReLU from PyTorch\n",
    "            self.add_module(f'layer_{i}', l)             # we need to register the modules explicitly\n",
    "        self.loss = nn.MSELoss()                         # we use the MSELoss from PyTorch\n",
    "        \n",
    "    def forward(self, x, y):\n",
    "        for l in self.layers: x = l(x)\n",
    "        return self.loss(x.squeeze(-1), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9fd6ac-0fa7-41c1-a05e-45b26ca2257d",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Autograd needs all tensors to be float\n",
    "x_train = x_train.to(torch.float32)\n",
    "y_train = y_train.to(torch.float32)\n",
    "m = Model(n_in, n_h, n_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e8fb58-c93b-4776-995b-a93e062ff34e",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def fit(epochs):\n",
    "    for epoch in range(epochs):\n",
    "        for i in range(0,len(x_train), bs):\n",
    "            xb = x_train[i:i+bs]\n",
    "            yb = y_train[i:i+bs]\n",
    "\n",
    "            loss = m(xb, yb)\n",
    "            loss.backward()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for p in m.parameters():\n",
    "                    p -= lr * p.grad\n",
    "                m.zero_grad()\n",
    "        print(f'{epoch=} | {loss=:.1f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c556fdc9-b6e8-4612-804f-9776d30978cb",
   "metadata": {},
   "source": [
    "## Fourth refactor: `nn.ModuleList` and `nn.Sequential`\n",
    "\n",
    "To simplify the storing of the layers array and the registration of the modules, we can use `nn.ModuleList`. Up till now, we compute the loss as part of the forward pass of the model, let's change that and let the model return the predictions. With these predictions we can now also compute a metric: accuracy, which will represent the percentage of images correctly classified by the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6f4432-1256-4aee-89cb-b1ea96c1d3a4",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, n_in, n_h, n_out):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList([nn.Linear(n_in, n_h), nn.ReLU(), nn.Linear(n_h, n_out)])\n",
    "        \n",
    "    def forward(self, x, y):\n",
    "        for l in self.layers: x = l(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd5e434-3271-46f5-b8b3-e298f41178fb",
   "metadata": {},
   "source": [
    "This turns out to be such an elementary operation, that PyTorch has a module for it: `nn.Sequential`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55e37c3-2196-4c91-9d95-0597c01f85ad",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "layers = [nn.Linear(n_in,n_h), nn.ReLU(), nn.Linear(n_h, n_out)]\n",
    "model = nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4510d8ae",
   "metadata": {},
   "source": [
    "And let's update our training loop as we mentioned:\n",
    "\n",
    "- The loss needs to be computed separately, since we took it out of the model\n",
    "- Let's now also use a loss function that actually makes sense: cross entropy loss instead of MSE\n",
    "- We then need to switch back to using 10 output activations conforming with the 10 categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce72fb8f-5cab-42f0-b258-ef7e8a5e4b86",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "n_out = 10\n",
    "\n",
    "layers = [nn.Linear(n_in,n_h), nn.ReLU(), nn.Linear(n_h, n_out)]\n",
    "model = nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "391d0fd9-1c71-4f56-b49f-0bb72a9e95e7",
   "metadata": {},
   "source": [
    "Let's also add a metric: accuracy, to see how our model is doing. For this, we need to find the class that our model predicts. However, the model is outputting not a single class, it outputs *logits*: the unweighted predictions for any of the 10 classes. When applying a softmax to these logits, we turn them into 10 probabilities: the probability that our model assigns to each class.\n",
    "\n",
    "When computing the accuracy, we don't actually just use the logits instead of the probabilities, since the softmax is a monotonically increasing we largest logit, will also have the largest probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d2c4f4-c4a1-4005-abfb-0358df3e8801",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits=tensor([-0.1345,  0.1549, -0.0635,  0.0619,  0.0516, -0.0358,  0.1625, -0.0322,\n",
      "        -0.0614,  0.1931], grad_fn=<AddBackward0>)\n",
      "probs=tensor([0.0844, 0.1127, 0.0906, 0.1027, 0.1016, 0.0931, 0.1136, 0.0935, 0.0908,\n",
      "        0.1171], grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x0 = x_train[0]\n",
    "logits = model(x0)\n",
    "\n",
    "print(f'{logits=}')                           # Logit output of the model\n",
    "\n",
    "probs = logits.softmax(dim=0)\n",
    "\n",
    "print(f'{probs=}')                            # class probabilites\n",
    "\n",
    "assert torch.allclose(probs.sum(),            # probabilities sum to 1\n",
    "                      torch.tensor(1.0))      \n",
    "\n",
    "assert torch.all(probs > 0)                   # no negative probabilities\n",
    "\n",
    "assert (logits.argmax() == probs.argmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427ced63-a6e8-407c-887d-a3e63629db4c",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def accuracy(preds, targs):\n",
    "    return (preds.argmax(dim=1) == targs).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db57fe5a-5dfe-4957-ab7c-6a47a85724c5",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=0 | loss=1.071 | acc=0.684\n",
      "epoch=1 | loss=0.992 | acc=0.681\n",
      "epoch=2 | loss=0.934 | acc=0.688\n",
      "epoch=3 | loss=0.889 | acc=0.697\n",
      "epoch=4 | loss=0.853 | acc=0.706\n"
     ]
    }
   ],
   "source": [
    "loss_func = F.cross_entropy\n",
    "y_train = y_train.to(torch.long)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for i in range(0,len(x_train), bs):\n",
    "        xb = x_train[i:i+bs]\n",
    "        yb = y_train[i:i+bs]\n",
    "\n",
    "        preds = model(xb)\n",
    "        acc = accuracy(preds, yb)\n",
    "        loss = loss_func(preds, yb)\n",
    "        loss.backward()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for p in model.parameters():\n",
    "                p -= lr * p.grad\n",
    "            model.zero_grad()\n",
    "    print(f'{epoch=} | {loss=:.3f} | {acc=:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14361c7-877e-4d84-ae67-218cfd0f25be",
   "metadata": {},
   "source": [
    "## Fifth refactor: add an Optimizer\n",
    "\n",
    "We can further refactor the model by adding an Optimizer, this is an object that will have access to the `parameters` and does the updating of the weights (`step`) and zeroing the gradient. Most notably, we want to go from:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0abedc9a",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# ...\n",
    "# with torch.no_grad():\n",
    "#     for p in model.parameters():\n",
    "#         p -= lr * p.grad\n",
    "#     model.zero_grad()\n",
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86cb58c3",
   "metadata": {},
   "source": [
    "to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efcf8b4f",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# opt.step()\n",
    "# opt.zero_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b51a265c",
   "metadata": {},
   "source": [
    "So that the training loop becomes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600a8706",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def fit(epochs):\n",
    "    for epoch in range(epochs):\n",
    "        for i in range(0,len(x_train), bs):\n",
    "            xb = x_train[i:i+bs]\n",
    "            yb = y_train[i:i+bs]\n",
    "\n",
    "            preds = model(xb)\n",
    "            acc = accuracy(preds, yb)\n",
    "            loss = loss_func(preds, yb)\n",
    "            loss.backward()\n",
    "\n",
    "            opt.step()                       # optimizer takes care of the weight update\n",
    "            opt.zero_grad()                  # as well as zeroing the grad\n",
    "        print(f'{epoch=} | {loss=:.3f} | {acc=:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59921c06",
   "metadata": {},
   "source": [
    "So we introduce the Optimizer, which has exactly these two methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1287c26-f23d-461b-af71-9816f23a70e5",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "class Optimizer():\n",
    "    def __init__(self, params, lr=0.5):\n",
    "        self.params = list(params)\n",
    "        self.lr = lr\n",
    "        \n",
    "    def step(self):\n",
    "        with torch.no_grad():\n",
    "            for p in self.params: p -= self.lr * p.grad\n",
    "        \n",
    "    def zero_grad(self):\n",
    "        with torch.no_grad():\n",
    "            for p in self.params: p.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0ac1c8-a84d-46a3-acd4-8b3c8941d5cf",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "layers = [nn.Linear(n_in,n_h), nn.ReLU(), nn.Linear(n_h, n_out)]\n",
    "model = model = nn.Sequential(*layers)\n",
    "opt = Optimizer(model.parameters(), lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c6b279-7aa1-42b4-968c-e30e1082bc83",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=0 | loss=2.074 | acc=0.447\n",
      "epoch=1 | loss=1.832 | acc=0.582\n",
      "epoch=2 | loss=1.571 | acc=0.653\n",
      "epoch=3 | loss=1.354 | acc=0.676\n",
      "epoch=4 | loss=1.195 | acc=0.673\n"
     ]
    }
   ],
   "source": [
    "fit(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d905c0c-30f5-4ea6-9729-78aeb8ab9e6d",
   "metadata": {},
   "source": [
    "The optimizer we just created is basically the `SGD` optimizer from PyTorch so let's use that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1fa5fc-6f80-4fa6-b25e-8ee285f09f30",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=0 | loss=2.026 | acc=0.456\n",
      "epoch=1 | loss=1.751 | acc=0.559\n",
      "epoch=2 | loss=1.502 | acc=0.605\n",
      "epoch=3 | loss=1.314 | acc=0.630\n",
      "epoch=4 | loss=1.179 | acc=0.635\n"
     ]
    }
   ],
   "source": [
    "def get_model():\n",
    "    layers = [nn.Linear(n_in, n_h), nn.ReLU(), nn.Linear(n_h, n_out)]\n",
    "    model = nn.Sequential(*layers)\n",
    "    \n",
    "    opt = torch.optim.SGD(model.parameters(), lr)\n",
    "    \n",
    "    return model, opt\n",
    "\n",
    "model, opt = get_model()\n",
    "fit(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43691738-3c7d-4f12-8ec1-5743111ba2be",
   "metadata": {},
   "source": [
    "## End\n",
    "\n",
    "We have come a long way, and covered a lot of ground. We have seen many of the fundamental components of training a neural network: the data, a simple model, training loops, loss functions, metrics and optimizers. We have seen why things like `nn.Module` exist, and understand it's behavior. Furthermore, we have seen that the need for `nn.Module` and `torch.optim` comes out of the need for simplifying things in the training loop.\n",
    "\n",
    "In the next post, we will get to datasets and dataloaders as a way to further improve the training loop, and we will start adding our first things into the `nntrain` library üï∫."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c9e1cb5",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
