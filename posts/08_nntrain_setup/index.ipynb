{
 "cells": [
  {
   "cell_type": "raw",
   "id": "5a706372-b4f8-4d32-9470-24b837947fa5",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"`nntrain`: preliminaries (0/n)\"\n",
    "author: \"Lucas van Walstijn\"\n",
    "date: \"2023-08-09\"\n",
    "categories: [Code, Neural Network, Deep Learning]\n",
    "image: \"image.jpeg\"\n",
    "comments:\n",
    "  utterances:\n",
    "    repo: lucasvw/BlogComments\n",
    "format:\n",
    "  html:\n",
    "    code-overflow: wrap\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "438a6911-402a-4234-9a58-7e1530bcb1bb",
   "metadata": {},
   "source": [
    "In this series, I want to discuss the creation of a small library for training neural networks: `nntrain`. It's based off the excellent [part 2](https://course.fast.ai/) of Practical Deep Learning for Coders by Jeremy Howard, in which from lessons 13 to 18 (roughly) the development of the `miniai` library is discussed.\n",
    "\n",
    "The library will build upon PyTorch. However, we'll create things as much as possible from scratch to understand how it all works. Once the main functionality of components are implemented and verified, we can use PyTorch's version, mainly for performance reasons and interoperability. This is similar to how things are done in the course. I explicitly want to state here that it's not just a \"copy / paste\" of the course. On many occasions I take a different route, and most of the code is my own."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc98b7c4-9002-407d-90f6-ea9d8c07b8ae",
   "metadata": {},
   "source": [
    "As we'll see, the library will be built using [`nb_dev`](https://nbdev.fast.ai/), another great project from the fastai community. With this software, it becomes very straight forward to create python libraries which are exported from jupyter notebooks. This may sound a bit weird, but it has the advantage that we can create the sourcecode for our library in the very same environment in which we want to experiment and interact with our methods, objects and structure **while we are building the library**. For more details on why this is a good idea, see [here](https://www.fast.ai/posts/2022-07-28-nbdev2.html).\n",
    "\n",
    "So without further ado, let's start with some data!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "349f4381",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a4b6e1-9737-470a-980b-1aa3df5f5268",
   "metadata": {},
   "source": [
    " To keep things simple, let's use the fashion-mnist dataset. We can get the data from the huggingface datasets library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4de5add-ae69-46ee-aa4f-a38487830fa9",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fashion-MNIST is a dataset of Zalando's article imagesâ€”consisting of a training set of\n",
      "60,000 examples and a test set of 10,000 examples. Each example is a 28x28 grayscale image,\n",
      "associated with a label from 10 classes. We intend Fashion-MNIST to serve as a direct drop-in\n",
      "replacement for the original MNIST dataset for benchmarking machine learning algorithms.\n",
      "It shares the same image size and structure of training and testing splits.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset,load_dataset_builder\n",
    "\n",
    "name = \"fashion_mnist\"\n",
    "ds_builder = load_dataset_builder(name)\n",
    "print(ds_builder.info.description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a70f9b3-fef1-4a54-bf22-581c9f651a7e",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset fashion_mnist (/root/.cache/huggingface/datasets/fashion_mnist/fashion_mnist/1.0.0/8d6c32399aa01613d96e2cbc9b13638f359ef62bb33612b077b4c247f6ef99c1)\n"
     ]
    }
   ],
   "source": [
    "ds = load_dataset(name, split='train')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba93a563-aac7-4015-9a95-c42d8d3d3749",
   "metadata": {},
   "source": [
    "`ds` is a `Dataset` object. These kind of objects appear in many Deep Learning libraries and have two main functionalities: you can index into them and they have a length:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3960543f-0fdb-4316-aef8-a3d51a42e287",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image': <PIL.PngImagePlugin.PngImageFile image mode=L size=28x28>,\n",
       " 'label': 9}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71add5de-4c4f-45bb-a694-606dd45603b2",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ea37f9-7d1e-45e0-9840-dd79d47f828d",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['image', 'label'],\n",
       "    num_rows: 60000\n",
       "})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ade5bd0-9411-4f7c-9f18-634f84931e72",
   "metadata": {},
   "source": [
    "Hugginface datasets (as opposed to PyTorch datasets) also have some properties, in this case `num_rows`, which is the length of the dataset (60000) and `features`, a dictionary giving metadata on what is returned when we index into the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4059340-2d94-4fba-be7a-2dae8760bc04",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image': Image(decode=True, id=None),\n",
       " 'label': ClassLabel(num_classes=10, names=['T - shirt / top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot'], id=None)}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5524187-43f6-484b-ac44-ae581ba3dec7",
   "metadata": {},
   "source": [
    "Let's visualize one single item:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b83ab5-7852-4b6d-91c6-30e7403dead2",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "image = ds[0]['image']\n",
    "label = ds[0]['label']\n",
    "\n",
    "figure, axs = plt.subplots()\n",
    "\n",
    "axs.imshow(ds[0]['image'], cmap='Greys')\n",
    "axs.set_title(f'Image of the first item in the dataset: label={label} -> \"{ds.features[\"label\"].int2str(label)}\"');\n",
    "axs.axis('off');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f5f664a-7e41-41a5-bf47-6e97189034a1",
   "metadata": {},
   "source": [
    "Since we want to start simple, and only later get to Datsets and Dataloaders: let's pull out the data into a tensor so we can build simple linear layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced0c08f-7529-409f-9595-3ab96a701a35",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 60000, 784)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torchvision.transforms.functional as TF   # to transform from PIL to tensor\n",
    "import torch\n",
    "\n",
    "x_train = [TF.to_tensor(i).view(-1) for i in ds['image']]\n",
    "y_train = [torch.tensor(i) for i in ds['label']]\n",
    "\n",
    "len(x_train), len(y_train), len(x_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf3867f",
   "metadata": {},
   "source": [
    "So `x_train` and `y_train` are both lists of length 60000, and an element in `x_train` has length 784 (28x28 pixels)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adde1eab",
   "metadata": {},
   "source": [
    "## Linear layers\n",
    "\n",
    "Now that we have the data, let's create our very first network operation: a linear layer which takes the 784 long flattened out image vector, and maps it to an output vector of length 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ccde6f-7b74-479b-b841-f8864033ab3f",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def lin(x, a, b):\n",
    "    return x@a + b\n",
    "\n",
    "a = torch.randn(784, 10)\n",
    "b = torch.randn(10)\n",
    "\n",
    "out = lin(x_train[0], a, b)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae6f7f3",
   "metadata": {},
   "source": [
    ":::{.callout-note}\n",
    "For details on matrix multiplications, check out this [post](https://lucasvw.github.io/posts/04_matmul/) I wrote earlier. \n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18210f04-74f8-4e1d-9f0e-7d93c4e1e4fc",
   "metadata": {},
   "source": [
    "Let's do the same for all our training data at once:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf8ca7b-50e3-435d-bb92-894eeb46a573",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 10])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = torch.stack(x_train)\n",
    "out = lin(x_train, a,b)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9796dee-5fd2-4765-9fb9-e8ae0e66d7fd",
   "metadata": {},
   "source": [
    "Nice, that's basically a forward pass through our model on all our training data! \n",
    "\n",
    "Now if we want to increase the depth of our network by adding an additional layer, we need to add a non-linearity in the middle. Why? See for example the first paragraphs of this [answer](https://stats.stackexchange.com/a/335972). \n",
    "\n",
    "Let's add a ReLu nonlinearity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41af6235-55e6-4cc6-af39-e9457945a955",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    return x.clamp_min(0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52437d1e-4d94-4181-9512-db8a2ea75aeb",
   "metadata": {},
   "source": [
    "And let's combine these into our first \"model\", consisting of two linear layers and a relu nonlinearity in the middle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36844072-8ec7-4c06-9b1f-cc966d45027c",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "n_in = 784 # number of input units (28x28)\n",
    "n_h = 50   # number of hidden units\n",
    "n_out = 10 # number of output units\n",
    "\n",
    "w1 = torch.randn(n_in, n_h)\n",
    "b1 = torch.zeros(n_h)\n",
    "w2 = torch.randn(n_h, n_out)\n",
    "b2 = torch.zeros(n_out)\n",
    "\n",
    "def model(x):\n",
    "    a1 = lin(x, w1, b1)\n",
    "    z1 = relu(a1)\n",
    "    return lin(z1, w2, b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374c9742-defa-4544-a183-3d362616f1b9",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "out = model(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae45976-f263-411b-baf9-13ad07d9f113",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 10])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615e4efe-fc6d-4ab9-b208-c2f6947e6a6d",
   "metadata": {},
   "source": [
    "Our \"model\" currently only does a forward pass through the network. And as a matter of fact, it's doing a forward pass with random weights. When training a neural network, we want to change these parameters in a way that the outputs of the network align with the outputs (`y_train`). I will not go into the details of this, but here is a great [video](https://youtu.be/VMj-3S1tku0) by Andrej Karpathy which in my opinion gives one of the best explanations into how this works.\n",
    "\n",
    "Before doing a backward pass, we first have to calculate the loss. Since the outputs represent any of the 10 classes the image corresponds with,  cross entropy is a straight forward loss function. Some details about cross entropy loss can be found in a [post](https://lucasvw.github.io/posts/05_crossentropy/) I wrote earlier. However, since we want to add the backpropagation ourselves and I don't know how to backpropagate through cross entropy (and I don't feel like spending a lot of time on it), let's use a much easier loss function for now: mean squared error (MSE). This obviously doesn't make any sense in the context of our data, but mathematically it's possible. We just have to end up with a single activation of our model instead of 10:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4499b9-baeb-4fd9-b99e-c97155ec0e4a",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "n_out = 1  # number of output units changed to 1\n",
    "\n",
    "w2 = torch.randn(n_h, n_out)\n",
    "b2 = torch.zeros(n_out)\n",
    "\n",
    "def model(x):\n",
    "    a1 = lin(x, w1, b1)\n",
    "    z1 = relu(a1)\n",
    "    return lin(z1, w2, b2)\n",
    "\n",
    "out = model(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58bb243-b528-4595-91c9-f1a6404112e6",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 1])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b55a9d-2006-46ae-8df6-2c939940d13d",
   "metadata": {},
   "source": [
    "From which we see that the outputs have an empty trailing dimension. `y_train` doesn't have this, so we have to squeeze out this empty dimension when computing the MSE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7542ce-91e4-44a5-95bd-934252611d86",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(757.6417)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mse(pred, targ): \n",
    "    return (pred.squeeze(-1)-targ).pow(2).mean() \n",
    "\n",
    "y_train = torch.stack(y_train)\n",
    "mse(out, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70062151-3121-4c1a-80b9-b88e071290ed",
   "metadata": {},
   "source": [
    "The next step will be to add the backward pass. But let's refactor our code to put things into classes, that way the backward pass can be added more easily:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256b9f6a-59c4-47f2-af46-dbabb2716f34",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "class Linear():\n",
    "    def __init__(self, n_in, n_out):\n",
    "        self.w = torch.randn(n_in, n_out)\n",
    "        self.b = torch.zeros(n_out)\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        self.inp = x                      # storing this for the backward pass\n",
    "        self.out = x@self.w + self.b      # storing this for the backward pass\n",
    "        return self.out\n",
    "    \n",
    "class Relu():\n",
    "    def __call__(self, x):\n",
    "        self.inp = x                      # storing this for the backward pass\n",
    "        self.out = x.clamp_min(0.)        # storing this for the backward pass\n",
    "        return self.out\n",
    "    \n",
    "class MSE():\n",
    "    def __call__(self, pred, targ):\n",
    "        self.pred = pred                   # storing this for the backward pass\n",
    "        self.targ = targ                   # storing this for the backward pass\n",
    "        self.out = (pred.squeeze(-1)-targ).pow(2).mean()\n",
    "        return self.out\n",
    "    \n",
    "class Model():\n",
    "    def __init__(self, n_in, n_h, n_out):\n",
    "        self.layers = [Linear(n_in, n_h), Relu(), Linear(n_h, n_out)]\n",
    "        self.loss = MSE()\n",
    "        \n",
    "    def __call__(self, x, y):\n",
    "        for l in self.layers: x = l(x)\n",
    "        return self.loss(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96646d9f-cee9-44a5-81e5-4c37c3dd94f6",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 784])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6221762e-001e-4251-a10f-935aeb60959b",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "m = Model(n_in, n_h, n_out)\n",
    "l = m(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a441f0-fa7a-419c-ae27-4cc8e79780b4",
   "metadata": {},
   "source": [
    "To add in the functionality for the backward pass, redefining the whole class is a nuisance. So instead we'll `patch` the classes. We can do this very easily by using the `fastcore` library. Let's see a small example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60baf247-adb4-4af5-81d9-107c6fbdf2be",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello ðŸ˜Ž\n",
      "howdy ðŸ¤ \n"
     ]
    }
   ],
   "source": [
    "import fastcore.all as fc\n",
    "\n",
    "class A():\n",
    "    def hi(self): print('hello ðŸ˜Ž')\n",
    "    \n",
    "a = A()\n",
    "a.hi()\n",
    "\n",
    "@fc.patch\n",
    "def hi(self:A): print('howdy ðŸ¤ ')\n",
    "\n",
    "a.hi()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f3eb88",
   "metadata": {},
   "source": [
    "So with `fc.patch` we can extend or change the behavior of Classes that have been defined elsewhere, even on instances of the objects that are already created. Nice!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d160fba4-2957-4aef-a351-1b55a13bdfb1",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "@fc.patch\n",
    "def backward(self: Linear):\n",
    "    self.inp.g = self.out.g @ self.w.t()\n",
    "    self.w.g = self.inp.t() @ self.out.g\n",
    "    self.b.g = self.out.g.sum(0)\n",
    "    \n",
    "@fc.patch\n",
    "def backward(self: Relu):\n",
    "    self.inp.g = (self.inp>0).float() * self.out.g\n",
    "    \n",
    "@fc.patch\n",
    "def backward(self: MSE):\n",
    "    self.pred.g = 2. * (self.pred.squeeze() - self.targ).unsqueeze(-1) / self.targ.shape[0]\n",
    "    \n",
    "@fc.patch\n",
    "def backward(self: Model):\n",
    "    self.loss.backward()\n",
    "    for l in reversed(self.layers): l.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95417fa-a50e-401e-b3b3-ffc20c48fb57",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "m = Model(n_in, n_h, n_out)\n",
    "l = m(x_train, y_train)\n",
    "m.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "863ee419-38b3-45e3-815f-b7d2f6aea0fd",
   "metadata": {},
   "source": [
    "Now the actual operations in the backward methods you will just have to take for granted as I am not going to derive them. If you want, you can have some fun (?) to try and derive it yourself. What I think is most important about these formulas:\n",
    "\n",
    "1. Notice that each layer has a reference to it's inputs and it's outputs\n",
    "2. During the backward pass, each layer uses the gradient from the *outputs* and uses it to set the gradient on the *inputs*\n",
    "3. The inputs from layer $n$ are the outputs from layer $n-1$, so when the gradients are being set on the inputs from layer $n$, this means that layer $n-1$ it's outputs are being set at the same time\n",
    "4. This is the fundamental point about backpropagation of the gradient: in reverse order, layer by layer the gradients are being *propagated back* through the network using the chain rule\n",
    "5. Although we don't derive the operations, we can see that that there *exist* operations that do this. These operations are not magical, they are just the result of calculus: not very different from the fact that if $f(x) = x^2$ then $f'(x) = 2x$ and if $h(x) = f(g(x))$ then $h'(x) = f'(g(x)) * g'(x)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93c9c85-467d-4cbc-a137-f631b3b82b08",
   "metadata": {},
   "source": [
    "## First refactor: `Module` baseclass and training loop\n",
    "\n",
    "Now let's see how we can make this a little better. One thing that seems a bit silly is that in each of the `Linear`, `MSE` and `Relu` classes, we are storing explicitly the inputs and outputs when doing a forward call. As mentioned, we need this to backpropagate the gradients. However, we rather not store that explicitly all the time when creating a new layer. \n",
    "\n",
    "So let's create a base class that takes care of this:\n",
    "\n",
    "- Pack the forward functionality of each layer in a dedicated `forward` method\n",
    "- let the storing of inputs and ouputs be done in the `__call__` method of the baseclass, and call the `self.forward` method in between.\n",
    "\n",
    "This works, but there is one caveat: most layers just have one input when they are called (`x`), but the loss has 2 (`pred` and `targ`). To make this storing of the inputs generic we can store them as an array on the base class, and also pass them as positional arguments to `_backward`. This way, `forward` and `_backward` have the same arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b50394e-2d69-4c4e-9393-d1d5a41bfda8",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "class Module():\n",
    "    def __call__(self, *args):\n",
    "        self.args = args\n",
    "        self.out = self.forward(*args)\n",
    "        return self.out\n",
    "    \n",
    "    def backward(self): self._backward(*self.args)\n",
    "\n",
    "    \n",
    "class Linear(Module):\n",
    "    def __init__(self, n_in, n_out):\n",
    "        self.w = torch.randn(n_in, n_out)\n",
    "        self.b = torch.zeros(n_out)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return x@self.w + self.b\n",
    "    \n",
    "    def _backward(self, inp):\n",
    "        inp.g = self.out.g @ self.w.t()\n",
    "        self.w.g = inp.t() @ self.out.g\n",
    "        self.b.g = self.out.g.sum(0)\n",
    "    \n",
    "    \n",
    "class Relu(Module):\n",
    "    def forward(self, x):\n",
    "        return x.clamp_min(0.)\n",
    "    \n",
    "    def _backward(self, inp):\n",
    "        inp.g = (inp>0).float() * self.out.g\n",
    "\n",
    "    \n",
    "class MSE(Module):\n",
    "    def forward(self, pred, targ):\n",
    "        return (pred.squeeze(-1)-targ).pow(2).mean()\n",
    "    \n",
    "    def _backward(self, pred, targ):\n",
    "        pred.g = 2. * (pred.squeeze() - targ).unsqueeze(-1) / targ.shape[0]\n",
    "    \n",
    "    \n",
    "class Model(Module):\n",
    "    def __init__(self, n_in, n_h, n_out):\n",
    "        self.layers = [Linear(n_in, n_h), Relu(), Linear(n_h, n_out)]\n",
    "        self.loss = MSE()\n",
    "        \n",
    "    def forward(self, x, y):\n",
    "        for l in self.layers: x = l(x)\n",
    "        return self.loss(x, y)\n",
    "    \n",
    "    def backward(self):\n",
    "        self.loss.backward()\n",
    "        for l in reversed(self.layers): l.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9429f9ce-9e65-4092-a55d-2c55c2fbd36f",
   "metadata": {},
   "source": [
    "With these objects, let's create our first training loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8b1027-bdbd-4f00-90a7-346b85fbf040",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=0 | loss=106694101172224.0\n",
      "epoch=1 | loss=9835971084288.0\n",
      "epoch=2 | loss=906763501568.0\n",
      "epoch=3 | loss=83593175040.0\n",
      "epoch=4 | loss=7706321408.0\n"
     ]
    }
   ],
   "source": [
    "epochs = 5                              # train for nr of epochs\n",
    "bs     = 1024                           # batch-size\n",
    "lr     = 0.01                           # learning rate\n",
    "m = Model(n_in, n_h, n_out)             # instantiate our model\n",
    "\n",
    "for epoch in range(epochs):             # iterate through epochs\n",
    "    for i in range(0,len(x_train), bs): # iterate through the batches\n",
    "        xb = x_train[i:i+bs]            # get minibatch \n",
    "        yb = y_train[i:i+bs]\n",
    "        \n",
    "        loss = m(xb, yb)                # forward pass\n",
    "        m.backward()                    # backward pass\n",
    "        \n",
    "        for l in m.layers:              # iterate through the layers\n",
    "            if isinstance(l, Linear):   # only update the linear layers\n",
    "                l.w += - lr * l.w.g     # update the weights\n",
    "                l.b += - lr * l.b.g     # update the bias\n",
    "\n",
    "                l.w.g = None            # reset the gradients\n",
    "                l.b.g = None\n",
    "    print(f'{epoch=} | {loss=:.1f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127d8944-5d93-423b-a0ea-55245b59b2be",
   "metadata": {},
   "source": [
    "Awesome, the loss is decreasing i.e. the model is training!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8fac5f4-d7ab-4def-bcc5-a57e2364d742",
   "metadata": {},
   "source": [
    "## Second refactor: simplify the weight update\n",
    "\n",
    "Let's try to simplify our training loop, and make it more generic. By adding functionality to our Module class so that it has a reference to it's trainable parameters, we can update the weights as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b672f76d-d436-4555-a660-0a9f8e31a2c4",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def fit(epochs):\n",
    "    for epoch in range(epochs):\n",
    "        for i in range(0,len(x_train), bs):\n",
    "            xb = x_train[i:i+bs]\n",
    "            yb = y_train[i:i+bs]\n",
    "\n",
    "            loss = m(xb, yb)\n",
    "            m.backward()\n",
    "\n",
    "            for p in m.parameters():    # model has a reference to the trainable parameters\n",
    "                p -= lr * p.g           \n",
    "            m.zero_grad()               # model can reset the gradients\n",
    "        print(f'{epoch=} | {loss=:.1f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2f0869-b537-4078-926f-279419154457",
   "metadata": {},
   "source": [
    "To do so, we will create a new baseclass (`NNModule`), from which our model and all the layers will inherit. We have the following conditions and properties:\n",
    "\n",
    "1. The class will hold a dictionary `_named_args`, in which all the named arguments are stored that are set on the Module.\n",
    "2. This is done by defining a `__setattr__` method, which stores any named argument that doesn't start with an `_` in this dictionary\n",
    "3. For the `Linear`, these named arguments will be the parameters `w` and `b`\n",
    "4. For the `Model`, these named arguments will be `layers` (an array containing the layer objects) and `loss` containing the `MSE` object.\n",
    "5. Because we want to get the parameters directly out of a layer, as well as out of the model, we need to implement some logic in `_parameters()` to iterate through the lowest \"level\" and get the actual parameters out\n",
    "6. Last but not least we have to implement a `zero_grad()` method to zero the gradients on the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa79b94-434b-4833-a673-01c8fa6065e0",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "class NNModule:\n",
    "    def __init__(self):\n",
    "        self._named_args = {}                           # [1]\n",
    "        \n",
    "    def __setattr__(self, name, value):                 # [2]\n",
    "        if not name.startswith(\"_\"): self._named_args[name] = value\n",
    "        super().__setattr__(name, value)\n",
    "        \n",
    "    def _parameters(self, obj):                         # [5]\n",
    "        for i in obj:\n",
    "            if isinstance(i, torch.Tensor): yield i\n",
    "            if isinstance(i, NNModule):\n",
    "                yield from iter(self._parameters(i._named_args.values()))\n",
    "            if isinstance(i, list):\n",
    "                yield from iter(self._parameters(i))\n",
    "        \n",
    "    def parameters(self):\n",
    "        return list(self._parameters(self._named_args.values()))\n",
    "    \n",
    "    def zero_grad(self):\n",
    "        for p in self.parameters():\n",
    "            p.g = None                                   # [6]\n",
    "        \n",
    "    def __call__(self, *args):\n",
    "        self._args = args                                # NOT stored under _named_args as \\\n",
    "        self._out = self.forward(*args)                  # it starts with \"_\"\n",
    "        return self._out\n",
    "    \n",
    "    def backward(self): self._backward(*self._args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94dc3d40-e209-47e2-89a8-77cc2b7d2ba4",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "class Linear(NNModule):\n",
    "    def __init__(self, n_in, n_out):\n",
    "        super().__init__()\n",
    "        self.w = torch.randn(n_in, n_out)               # [3] stored under _named_args \n",
    "        self.b = torch.zeros(n_out)                     # [3] stored under _named_args\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return x@self.w + self.b\n",
    "    \n",
    "    def _backward(self, inp):\n",
    "        inp.g = self._out.g @ self.w.t()\n",
    "        self.w.g = inp.t() @ self._out.g\n",
    "        self.b.g = self._out.g.sum(0)\n",
    "        \n",
    "        \n",
    "class Relu(NNModule):\n",
    "    def forward(self, x):\n",
    "        return x.clamp_min(0.)\n",
    "    \n",
    "    def _backward(self, inp):\n",
    "        inp.g = (inp>0).float() * self._out.g\n",
    "\n",
    "    \n",
    "class MSE(NNModule):\n",
    "    def forward(self, pred, targ):\n",
    "        return (pred.squeeze(-1)-targ).pow(2).mean()\n",
    "    \n",
    "    def _backward(self, pred, targ):\n",
    "        pred.g = 2. * (pred.squeeze() - targ).unsqueeze(-1) / targ.shape[0]\n",
    "        \n",
    "        \n",
    "class Model(NNModule):\n",
    "    def __init__(self, n_in, n_h, n_out):\n",
    "        super().__init__()\n",
    "        self.layers = [Linear(n_in, n_h), Relu(), Linear(n_h, n_out)]\n",
    "        self.loss = MSE()                              # [4] < and ^ are stored under _named_args\n",
    "        \n",
    "    def forward(self, x, y):\n",
    "        for l in self.layers: x = l(x)\n",
    "        return self.loss(x, y)\n",
    "    \n",
    "    def backward(self):\n",
    "        self.loss.backward()\n",
    "        for l in reversed(self.layers): l.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbefe737-7c6e-4bd5-8acc-90d1e55acc0b",
   "metadata": {},
   "source": [
    "And now we can indeed call `parameters` on both the model as well as on individual layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7be5f8-d881-44ed-966d-b34bdfd75198",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.Size([784, 50]), torch.Size([50]), torch.Size([50, 1]), torch.Size([1])]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = Model(n_in, n_h, n_out)\n",
    "[p.shape for p in m.parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd7411e-0428-446d-adec-a8be04afec81",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.Size([784, 50]), torch.Size([50])]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[p.shape for p in Linear(n_in, n_h).parameters()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c74b666-9f47-4d3d-8b02-5629790db8f3",
   "metadata": {},
   "source": [
    "Let's fit with our new training loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747d3927-1535-4a6b-abcb-5debb6d787e8",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=0 | loss=346.2\n",
      "epoch=1 | loss=39.9\n",
      "epoch=2 | loss=11.3\n",
      "epoch=3 | loss=8.6\n",
      "epoch=4 | loss=8.3\n"
     ]
    }
   ],
   "source": [
    "fit(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "277c05db-ec35-4c14-8b64-65f916ece110",
   "metadata": {},
   "source": [
    "## Third refactor: use `nn.Module`\n",
    "\n",
    "Finally we are in a position to use PyTorch's `nn.Module`, since we understand all of it's behavior! We can simplify:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ad3822-d3a0-4029-92d9-7e0654d9b21b",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, n_in, n_h, n_out):\n",
    "        super().__init__()\n",
    "        self.layers = [nn.Linear(n_in, n_h), nn.ReLU(), nn.Linear(n_h, n_out)]\n",
    "        for i,l in enumerate(self.layers):               # ^ we use the nn.Linear and nn.ReLU from PyTorch\n",
    "            self.add_module(f'layer_{i}', l)             # we need to register the modules explicitly\n",
    "        self.loss = nn.MSELoss()                         # we use the MSELoss from PyTorch\n",
    "        \n",
    "    def forward(self, x, y):\n",
    "        for l in self.layers: x = l(x)\n",
    "        return self.loss(x.squeeze(-1), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9fd6ac-0fa7-41c1-a05e-45b26ca2257d",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Autograd needs all tensors to be float\n",
    "x_train = x_train.to(torch.float32)\n",
    "y_train = y_train.to(torch.float32)\n",
    "m = Model(n_in, n_h, n_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e8fb58-c93b-4776-995b-a93e062ff34e",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def fit(epochs):\n",
    "    for epoch in range(epochs):\n",
    "        for i in range(0,len(x_train), bs):\n",
    "            xb = x_train[i:i+bs]\n",
    "            yb = y_train[i:i+bs]\n",
    "\n",
    "            loss = m(xb, yb)\n",
    "            loss.backward()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for p in m.parameters():\n",
    "                    p -= lr * p.grad\n",
    "                m.zero_grad()\n",
    "        print(f'{epoch=} | {loss=:.1f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c556fdc9-b6e8-4612-804f-9776d30978cb",
   "metadata": {},
   "source": [
    "## Fourth refactor: `nn.ModuleList` and `nn.Sequential`\n",
    "\n",
    "To simplify the storing of the layers array and the registration of the modules, we can use `nn.ModuleList`. Let's also take out the loss out of the model itself, and put that in the `fit` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6f4432-1256-4aee-89cb-b1ea96c1d3a4",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, n_in, n_h, n_out):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList([nn.Linear(n_in, n_h), nn.ReLU(), nn.Linear(n_h, n_out)])\n",
    "        \n",
    "    def forward(self, x, y):\n",
    "        for l in self.layers: x = l(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd5e434-3271-46f5-b8b3-e298f41178fb",
   "metadata": {},
   "source": [
    "This turns out to be such an elementary operation, that PyTorch has a module for it: `nn.Sequential`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55e37c3-2196-4c91-9d95-0597c01f85ad",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "layers = [nn.Linear(n_in,n_h), nn.ReLU(), nn.Linear(n_h, n_out)]\n",
    "model = nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4510d8ae",
   "metadata": {},
   "source": [
    "And let's update our training loop as we mentioned:\n",
    "\n",
    "- The loss needs to be computed separately, since we took it out of the model\n",
    "- Let's use cross entropy instead of MSE\n",
    "- For that we will switch back to using 10 outputs conforming with the 10 categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db57fe5a-5dfe-4957-ab7c-6a47a85724c5",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=0 | loss=1.702\n",
      "epoch=1 | loss=1.182\n",
      "epoch=2 | loss=1.068\n",
      "epoch=3 | loss=1.003\n",
      "epoch=4 | loss=0.864\n"
     ]
    }
   ],
   "source": [
    "n_out = 10\n",
    "layers = [nn.Linear(n_in,n_h), nn.ReLU(), nn.Linear(n_h, n_out)]\n",
    "model = nn.Sequential(*layers)\n",
    "\n",
    "loss_func = F.cross_entropy\n",
    "y_train = y_train.to(torch.long)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for i in range(0,len(x_train), bs):\n",
    "        xb = x_train[i:i+bs]\n",
    "        yb = y_train[i:i+bs]\n",
    "\n",
    "        preds = model(xb)\n",
    "        loss = loss_func(preds, yb)\n",
    "        loss.backward()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for p in model.parameters():\n",
    "                p -= lr * p.grad\n",
    "            model.zero_grad()\n",
    "    print(f'{epoch=} | {loss=:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14361c7-877e-4d84-ae67-218cfd0f25be",
   "metadata": {},
   "source": [
    "## Fifth refactor: add an Optimizer\n",
    "\n",
    "We can further refactor the model by adding an Optimizer, this is an object that will have access to the `parameters` and does the updating of the weights (`step`) and zeroing the gradient. Most notably, we want to go from:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0abedc9a",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "...\n",
    "with torch.no_grad():\n",
    "    for p in model.parameters():\n",
    "        p -= lr * p.grad\n",
    "    model.zero_grad()\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86cb58c3",
   "metadata": {},
   "source": [
    "to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efcf8b4f",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "opt.step()\n",
    "opt.zero_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b51a265c",
   "metadata": {},
   "source": [
    "So that the training loop becomes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600a8706",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def fit(epochs):\n",
    "    for epoch in range(epochs):\n",
    "        for i in range(0,len(x_train), bs):\n",
    "            xb = x_train[i:i+bs]\n",
    "            yb = y_train[i:i+bs]\n",
    "\n",
    "            preds = model(xb)\n",
    "            loss = loss_func(preds, yb)\n",
    "            loss.backward()\n",
    "\n",
    "            opt.step()                 \n",
    "            opt.zero_grad()\n",
    "        print(f'{epoch=} | {loss=:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59921c06",
   "metadata": {},
   "source": [
    "So we introduce the Optimizer, which has exactly these two methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1287c26-f23d-461b-af71-9816f23a70e5",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "class Optimizer():\n",
    "    def __init__(self, params, lr=0.5):\n",
    "        self.params = list(params)\n",
    "        self.lr = lr\n",
    "        \n",
    "    def step(self):\n",
    "        with torch.no_grad():\n",
    "            for p in self.params: p -= self.lr * p.grad\n",
    "        \n",
    "    def zero_grad(self):\n",
    "        with torch.no_grad():\n",
    "            for p in self.params: p.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0ac1c8-a84d-46a3-acd4-8b3c8941d5cf",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "layers = [nn.Linear(n_in,n_h), nn.ReLU(), nn.Linear(n_h, n_out)]\n",
    "model = model = nn.Sequential(*layers)\n",
    "opt = Optimizer(model.parameters(), lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c6b279-7aa1-42b4-968c-e30e1082bc83",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=0 | loss=0.666\n",
      "epoch=1 | loss=0.595\n",
      "epoch=2 | loss=0.493\n",
      "epoch=3 | loss=0.484\n",
      "epoch=4 | loss=0.427\n"
     ]
    }
   ],
   "source": [
    "\n",
    "fit(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d905c0c-30f5-4ea6-9729-78aeb8ab9e6d",
   "metadata": {},
   "source": [
    "The optimizer we just created is basically the `SGD` optimizer from PyTorch so let's use that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1fa5fc-6f80-4fa6-b25e-8ee285f09f30",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=0 | loss=0.979\n",
      "epoch=1 | loss=0.672\n",
      "epoch=2 | loss=0.499\n",
      "epoch=3 | loss=0.499\n",
      "epoch=4 | loss=0.432\n"
     ]
    }
   ],
   "source": [
    "def get_model():\n",
    "    layers = [nn.Linear(784,50), nn.ReLU(), nn.Linear(50,10)]\n",
    "    model = nn.Sequential(*layers)\n",
    "    \n",
    "    opt = torch.optim.SGD(model.parameters(), 0.5)\n",
    "    \n",
    "    return model, opt\n",
    "\n",
    "model, opt = get_model()\n",
    "fit(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43691738-3c7d-4f12-8ec1-5743111ba2be",
   "metadata": {},
   "source": [
    "## End\n",
    "\n",
    "We have come a long way, and covered a lot of ground. We have seen many of the fundamental components of training a neural network: the data, a simple model, training loops and optimizers. We have seen why things like `nn.Module` exist, and understand it's behavior. Furthermore, we have seen that the need for `nn.Module` and `torch.optim` comes out of the need for simplifying things.\n",
    "\n",
    "In the next post, we will get to datasets and dataloaders, and we will start adding our first things into the `nntrain` library ðŸ•º."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c9e1cb5",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
