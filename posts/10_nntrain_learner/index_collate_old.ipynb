{
 "cells": [
  {
   "cell_type": "raw",
   "id": "5a706372-b4f8-4d32-9470-24b837947fa5",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"`nntrain`: Learner (2/n)\"\n",
    "author: \"Lucas van Walstijn\"\n",
    "date: \"2023-08-16\"\n",
    "categories: [code, neural network, deep learning]\n",
    "image: \"image_2.jpg\"\n",
    "comments:\n",
    "  utterances:\n",
    "    repo: lucasvw/BlogComments\n",
    "format:\n",
    "  html:\n",
    "    code-overflow: wrap\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "438a6911-402a-4234-9a58-7e1530bcb1bb",
   "metadata": {},
   "source": [
    "In this series, I want to discuss the creation of a small library for training neural networks: `nntrain`. It's based off the excellent [part 2](https://course.fast.ai/) of Practical Deep Learning for Coders by Jeremy Howard, in which from lessons 13 to 18 (roughly) the development of the `miniai` library is discussed.\n",
    "\n",
    "The library will build upon PyTorch. We'll try as much as possible to build from scratch to understand how it all works. Once the main functionality of components are implemented and verified, we can switch over to PyTorch's version. This is similar to how things are done in the course. However, this is not just a \"copy / paste\" of the course: on many occasions I take a different route, and most of the code is my own. That is not to say that all of this is meant to be extremely innovative, instead I had the following goals:\n",
    "\n",
    "- Deeply understand the training of neural networks with a focus on PyTorch\n",
    "- Try to create an even better narrative then what's presented in FastAI üôâü§∑‚Äç‚ôÇÔ∏èüôà\n",
    "- Get hands-on experience with creating a library with [`nb_dev`](https://nbdev.fast.ai/)\n",
    "\n",
    "`nb_dev` is another great project from the fastai community, which allows python libraries to be written in jupyter notebooks. This may sound a bit weird since the mainstream paradigm is to only do experimental work in notebooks. It has the advantage though that we can create the source code for our library in the very same environment in which we want to experiment and interact with our methods, objects and structure **while we are building the library**. For more details on why this is a good idea and other nice features of `nb_dev`, see [here](https://www.fast.ai/posts/2022-07-28-nbdev2.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc98b7c4-9002-407d-90f6-ea9d8c07b8ae",
   "metadata": {},
   "source": [
    "So without further ado, let's start with where we left off in the previous [post](https://lucasvw.github.io/posts/08_nntrain_setup/):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de55ab2-bd58-40fe-8d16-7e9507741c5e",
   "metadata": {},
   "source": [
    "## End of last post:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "358815f3-be5d-4afa-b1d3-60f7f5524988",
   "metadata": {},
   "source": [
    "We finished last post with exporting the `dataloaders` module which helps transforming a huggingface dataset dictionary into PyTorch dataloaders, so let's use that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799ee285-5cc1-40df-b18d-82c93ab28f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# sys.path.append('/notebooks/nntrain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1872102-8494-432b-814c-8af6f423581e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nntrain.dataloaders import DataLoaders, hf_ds_collate_fn\n",
    "from datasets import load_dataset,load_dataset_builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e89e8e3-da05-4b23-91db-36909044152e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset fashion_mnist (/root/.cache/huggingface/datasets/fashion_mnist/fashion_mnist/1.0.0/8d6c32399aa01613d96e2cbc9b13638f359ef62bb33612b077b4c247f6ef99c1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2ef1797db834c4a86ebe39781c5bb2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(<torch.utils.data.dataloader.DataLoader>,\n",
       " <torch.utils.data.dataloader.DataLoader>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name = \"fashion_mnist\"\n",
    "ds_builder = load_dataset_builder(name)\n",
    "hf_dd = load_dataset(name)\n",
    "\n",
    "bs = 1024\n",
    "dls = DataLoaders.from_hf_dd(hf_dd, batch_size=bs)\n",
    "\n",
    "# As a reminder, `DataLoaders` expose a PyTorch train and validation dataloader as `train` and `valid` attributes:\n",
    "\n",
    "dls.train, dls.valid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665d6ae8-f4b6-45ff-90da-3b815cca654e",
   "metadata": {},
   "source": [
    "And the training loop we have so far:\n",
    "\n",
    "```{.python code-line-numbers='true'}\n",
    "def fit(epochs):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()                                       \n",
    "        n_t = train_loss_s = 0                              \n",
    "        for xb, yb in dls.train:\n",
    "            preds = model(xb)\n",
    "            train_loss = loss_func(preds, yb)\n",
    "            train_loss.backward()\n",
    "            \n",
    "            n_t += len(xb)\n",
    "            train_loss_s += train_loss.item() * len(xb)\n",
    "            \n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "        \n",
    "        model.eval()                                        \n",
    "        n_v = valid_loss_s = acc_s = 0                      \n",
    "        for xb, yb in dls.valid: \n",
    "            with torch.no_grad():                           \n",
    "                preds = model(xb)\n",
    "                valid_loss = loss_func(preds, yb)\n",
    "                \n",
    "                n_v += len(xb)\n",
    "                valid_loss_s += valid_loss.item() * len(xb)\n",
    "                acc_s += accuracy(preds, yb) * len(xb)\n",
    "        \n",
    "        train_loss = train_loss_s / n_t                     \n",
    "        valid_loss = valid_loss_s / n_v\n",
    "        acc = acc_s / n_v\n",
    "        print(f'{epoch=} | {train_loss=:.3f} | {valid_loss=:.3f} | {acc=:.3f}')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c071594b-a213-45b9-a186-132c54d52981",
   "metadata": {},
   "source": [
    "Now let's see if we can train this on the GPU instead of the CPU. For that we have to move all our tensors to the GPU: notably:\n",
    "\n",
    "- the data tensors in the dataloaders\n",
    "- all parameters of our model, i.e. the weight and bias tensors from each layer\n",
    "\n",
    "So let's first define a variable that will represent whether we can train on the GPU or not:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ad123a-3286-4c69-aded-ac67263f4f23",
   "metadata": {},
   "source": [
    "To put the model onto the GPU we can simply update:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1c96eb-e570-42e3-ae6a-80f4d94b079c",
   "metadata": {},
   "outputs": [],
   "source": [
    " #| export\n",
    "import torchvision.transforms.functional as TF\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34c3304-4425-4a88-9406-269c4a8793e2",
   "metadata": {},
   "outputs": [],
   "source": [
    " #| export\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095b88b7-d814-4828-8990-96b9c58ff4e7",
   "metadata": {},
   "source": [
    "Next, we can put the model (parameters) on the GPU when we instantiate it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99a8efe-b579-4fce-9c66-6a711f9babcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_opt():\n",
    "    layers = [nn.Linear(n_in, n_h), nn.ReLU(), nn.Linear(n_h, n_out)]\n",
    "    model = nn.Sequential(*layers).to(device)                # put the model on the device\n",
    "    \n",
    "    opt = torch.optim.SGD(model.parameters(), lr)\n",
    "    \n",
    "    return model, opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1fe583-c335-4694-a62c-77c915e21e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_device(data):\n",
    "    return to_device(hf_ds_collate_fn(data))\n",
    "\n",
    "dls = DataLoaders.from_hf_dd(hf_dd, batch_size=bs, collate_fn=collate_device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34044436-a607-4357-a71d-bd1b21d637a0",
   "metadata": {},
   "source": [
    "And let's verify that it works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b372c51-081f-4ce3-b4ae-3c6f3b091928",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_device(x):\n",
    "    return (o.to(device) for o in x)\n",
    "\n",
    "\n",
    "def fit(epochs):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()                                       \n",
    "        n_t = train_loss_s = 0                              \n",
    "        for xb, yb in dls.train:\n",
    "            preds = model(xb)\n",
    "            train_loss = loss_func(preds, yb)\n",
    "            train_loss.backward()\n",
    "            \n",
    "            n_t += len(xb)\n",
    "            train_loss_s += train_loss.item() * len(xb)\n",
    "            \n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "        \n",
    "        model.eval()                                        \n",
    "        n_v = valid_loss_s = acc_s = 0                      \n",
    "        for xb, yb in dls.valid: \n",
    "            with torch.no_grad():                           \n",
    "                preds = model(xb)\n",
    "                valid_loss = loss_func(preds, yb)\n",
    "                \n",
    "                n_v += len(xb)\n",
    "                valid_loss_s += valid_loss.item() * len(xb)\n",
    "                acc_s += accuracy(preds, yb) * len(xb)\n",
    "        \n",
    "        train_loss = train_loss_s / n_t                     \n",
    "        valid_loss = valid_loss_s / n_v\n",
    "        acc = acc_s / n_v\n",
    "        print(f'{epoch=} | {train_loss=:.3f} | {valid_loss=:.3f} | {acc=:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f628c383-3513-4cc9-9c58-b385202678f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=0 | train_loss=2.180 | valid_loss=2.047 | acc=0.495\n",
      "epoch=1 | train_loss=1.909 | valid_loss=1.769 | acc=0.582\n",
      "epoch=2 | train_loss=1.638 | valid_loss=1.519 | acc=0.633\n",
      "epoch=3 | train_loss=1.416 | valid_loss=1.330 | acc=0.646\n",
      "epoch=4 | train_loss=1.252 | valid_loss=1.194 | acc=0.653\n"
     ]
    }
   ],
   "source": [
    "def accuracy(preds, targs):\n",
    "    return (preds.argmax(dim=1) == targs).float().mean() \n",
    "\n",
    "n_in  = 28*28\n",
    "n_h   = 50\n",
    "n_out = 10\n",
    "lr    = 0.01\n",
    "bs    = 1024\n",
    "loss_func = F.cross_entropy\n",
    "\n",
    "model, opt = get_model_opt()\n",
    "\n",
    "fit(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c879d155-f5b5-469d-a9f9-a07fccf214c3",
   "metadata": {},
   "source": [
    "Nice, now we are training on the GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11819025-0be2-47cf-b529-ca72865f1e79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf601b9-cc64-4328-8f31-a9aab381bb63",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
